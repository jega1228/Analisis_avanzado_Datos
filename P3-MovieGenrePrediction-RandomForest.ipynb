{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 - Movie Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborado por GRUPO 1:\n",
    "\n",
    "- Juanita Piraban Barbosa - 201216313\n",
    "- Lorena Morales Rodríguez - 202027957\n",
    "- Alejandro Barinas Guio - 201628859\n",
    "- Jaime Humberto Trujillo Perea - 201920366\n",
    "- Alexander Zapata Galindo - 201425426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Classify a movie genre based on its plot.\n",
    "Source: https://www.kaggle.com/c/miia4201-202019-p3-moviegenreclassification/overview\n",
    "\n",
    "- Input: movie plot\n",
    "- Output: Probability of the movie belong to each genre\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "- 50% Report with all the details of the solution, the analysis and the conclusions. The report cannot exceed 10 pages, must be send in PDF format and must be self-contained.\n",
    "- 50% Performance in the Kaggle competition (The grade for each group will be proportional to the ranking it occupies in the competition. The group in the first place will obtain 5 points, for each position below, 0.25 points will be subtracted, that is: first place: 5 points, second: 4.75 points, third place: 4.50 points ... eleventh place: 2.50 points, twelfth place: 2.25 points).\n",
    "\n",
    "### Deatline\n",
    "\n",
    "- The project must be carried out in the groups assigned.\n",
    "- Use clear and rigorous procedures.\n",
    "- The delivery of the project is on August 1st, 2021, 11:59 pm, through Bloque Neón.\n",
    "- No projects will be received after the delivery time or by any other means than the one established.\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "We thank Professor Fabio Gonzalez, Ph.D. and his student John Arevalo for providing this dataset.\n",
    "See https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('DataSet/dataTraining.csv', encoding='UTF-8', index_col=0)\n",
    "df_test = pd.read_csv('Dataset/dataTesting.csv', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>['Short', 'Drama']</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1941</td>\n",
       "      <td>A Woman's Face</td>\n",
       "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
       "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>1954</td>\n",
       "      <td>Executive Suite</td>\n",
       "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>1990</td>\n",
       "      <td>Narrow Margin</td>\n",
       "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "6724  1941             A Woman's Face   \n",
       "4704  1954            Executive Suite   \n",
       "2582  1990              Narrow Margin   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "6724  in sweden ,  a female blackmailer with a disfi...   \n",
       "4704  in a friday afternoon in new york ,  the presi...   \n",
       "2582  in los angeles ,  the editor of a publishing h...   \n",
       "\n",
       "                                  genres  rating  \n",
       "3107                  ['Short', 'Drama']     8.0  \n",
       "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
       "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
       "4704                           ['Drama']     7.4  \n",
       "2582     ['Action', 'Crime', 'Thriller']     6.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7895 entries, 3107 to 215\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   year    7895 non-null   int64 \n",
      " 1   title   7895 non-null   object\n",
      " 2   plot    7895 non-null   object\n",
      " 3   genres  7895 non-null   object\n",
      " 4   rating  7895 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 370.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train['rating'] = df_train['rating'].astype(int)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Message in a Bottle</td>\n",
       "      <td>who meets by fate ,  shall be sealed by fate ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>Midnight Express</td>\n",
       "      <td>the true story of billy hayes ,  an american c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>Primal Fear</td>\n",
       "      <td>martin vail left the chicago da ' s office to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1950</td>\n",
       "      <td>Crisis</td>\n",
       "      <td>husband and wife americans dr .  eugene and mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959</td>\n",
       "      <td>The Tingler</td>\n",
       "      <td>the coroner and scientist dr .  warren chapin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                title  \\\n",
       "1  1999  Message in a Bottle   \n",
       "4  1978     Midnight Express   \n",
       "5  1996          Primal Fear   \n",
       "6  1950               Crisis   \n",
       "7  1959          The Tingler   \n",
       "\n",
       "                                                plot  \n",
       "1  who meets by fate ,  shall be sealed by fate ....  \n",
       "4  the true story of billy hayes ,  an american c...  \n",
       "5  martin vail left the chicago da ' s office to ...  \n",
       "6  husband and wife americans dr .  eugene and mr...  \n",
       "7  the coroner and scientist dr .  warren chapin ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3383 entries, 1 to 11275\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   year    3383 non-null   int64 \n",
      " 1   title   3383 non-null   object\n",
      " 2   plot    3383 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 105.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['genres'] = df_train['genres'].map(lambda x: eval(x))\n",
    "\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(df_train['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create count vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "vect = CountVectorizer(max_features=1000 , stop_words=english_stopwords, ngram_range=(1, 1))\n",
    "X_dtm = vect.fit_transform(df_train['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned', 'able', 'accepts', 'accident', 'accidentally', 'across', 'act', 'action', 'actor', 'actress', 'actually', 'adam', 'adult', 'adventure', 'affair', 'age', 'aged', 'agent', 'agents', 'ago', 'agrees', 'air', 'alan', 'alex', 'alice', 'alien', 'alive', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'america', 'american', 'among', 'ancient', 'andy', 'angeles', 'ann', 'anna', 'annie', 'another', 'anyone', 'anything', 'apart', 'apartment', 'appears', 'area', 'army', 'around', 'arrested', 'arrival', 'arrive', 'arrives', 'art', 'arthur', 'artist', 'asks', 'assigned', 'assistant', 'attack', 'attacked', 'attempt', 'attempts', 'attention', 'attorney', 'attracted', 'aunt', 'away', 'baby', 'back', 'bad', 'band', 'bank', 'bar', 'based', 'battle', 'beautiful', 'become', 'becomes', 'becoming', 'befriends', 'begin', 'beginning', 'begins', 'behavior', 'behind', 'believe', 'believes', 'beloved', 'ben', 'best', 'better', 'beyond', 'big', 'bill', 'billy', 'birthday', 'black', 'blood', 'blue', 'board', 'boat', 'bob', 'bobby', 'body', 'bond', 'book', 'born', 'boss', 'boy', 'boyfriend', 'boys', 'break', 'breaks', 'brian', 'bring', 'brings', 'british', 'broken', 'brother', 'brothers', 'brought', 'buddy', 'building', 'business', 'buy', 'california', 'call', 'called', 'calls', 'camp', 'cannot', 'captain', 'car', 'care', 'career', 'case', 'cat', 'caught', 'cause', 'causes', 'century', 'chance', 'change', 'changes', 'character', 'characters', 'charles', 'charlie', 'chicago', 'chief', 'child', 'childhood', 'children', 'choice', 'chris', 'christmas', 'church', 'cia', 'city', 'class', 'clear', 'close', 'club', 'co', 'coach', 'cold', 'college', 'colonel', 'come', 'comedy', 'comes', 'coming', 'committed', 'community', 'company', 'computer', 'con', 'contact', 'continue', 'control', 'convince', 'convinces', 'cop', 'cops', 'corrupt', 'could', 'count', 'country', 'couple', 'course', 'court', 'crash', 'crazy', 'crew', 'crime', 'criminal', 'criminals', 'cross', 'current', 'dad', 'dan', 'dance', 'danger', 'dangerous', 'daniel', 'danny', 'dark', 'date', 'daughter', 'dave', 'david', 'day', 'days', 'de', 'dead', 'deadly', 'deal', 'dealer', 'dealing', 'death', 'decide', 'decides', 'decision', 'deep', 'department', 'desert', 'desperate', 'despite', 'destroy', 'detective', 'determined', 'die', 'died', 'dies', 'different', 'difficult', 'director', 'dirty', 'discover', 'discovers', 'divorced', 'doctor', 'documentary', 'dog', 'door', 'doug', 'dr', 'dream', 'dreams', 'drive', 'driver', 'drug', 'drugs', 'due', 'dying', 'earlier', 'early', 'earth', 'easy', 'ed', 'eddie', 'effort', 'eight', 'either', 'elizabeth', 'ellen', 'else', 'encounter', 'encounters', 'end', 'ends', 'enemy', 'england', 'english', 'enough', 'enter', 'entire', 'escape', 'escapes', 'especially', 'estate', 'eve', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evidence', 'evil', 'ex', 'experience', 'eye', 'eyes', 'face', 'fact', 'fall', 'falling', 'falls', 'family', 'famous', 'far', 'farm', 'fast', 'fate', 'father', 'fbi', 'fear', 'feel', 'feeling', 'feelings', 'feels', 'fellow', 'female', 'fiancée', 'fight', 'fighting', 'figure', 'film', 'final', 'finally', 'find', 'finding', 'finds', 'fire', 'first', 'five', 'flight', 'follow', 'following', 'follows', 'food', 'football', 'force', 'forced', 'forces', 'forever', 'form', 'former', 'fortune', 'found', 'four', 'francisco', 'frank', 'free', 'freedom', 'french', 'friend', 'friends', 'friendship', 'front', 'full', 'fun', 'future', 'game', 'games', 'gang', 'gay', 'general', 'george', 'german', 'get', 'gets', 'getting', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'go', 'goal', 'god', 'goes', 'going', 'gold', 'gone', 'good', 'got', 'government', 'grace', 'great', 'group', 'growing', 'gun', 'guy', 'half', 'hand', 'hands', 'happen', 'happened', 'happens', 'happy', 'hard', 'harold', 'harry', 'head', 'heads', 'heart', 'helen', 'hell', 'help', 'helps', 'henry', 'hero', 'hidden', 'high', 'hired', 'hires', 'history', 'hit', 'hits', 'hold', 'hollywood', 'home', 'hope', 'hopes', 'horror', 'hospital', 'hotel', 'hours', 'house', 'however', 'huge', 'human', 'hunter', 'husband', 'idea', 'identity', 'immediately', 'important', 'incident', 'include', 'includes', 'including', 'indian', 'information', 'initially', 'innocent', 'inside', 'instead', 'interest', 'investigate', 'investigation', 'invites', 'involved', 'island', 'issues', 'jack', 'jail', 'jake', 'james', 'jane', 'japanese', 'jeff', 'jerry', 'jim', 'jimmy', 'job', 'joe', 'john', 'johnny', 'join', 'joins', 'journey', 'judge', 'justice', 'karen', 'kate', 'keep', 'keeps', 'kid', 'kidnapped', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'king', 'know', 'knowing', 'known', 'knows', 'la', 'lady', 'land', 'large', 'largely', 'larry', 'last', 'late', 'later', 'latest', 'law', 'lawyer', 'lead', 'leader', 'leading', 'leads', 'learn', 'learns', 'leave', 'leaves', 'leaving', 'led', 'lee', 'left', 'less', 'let', 'lies', 'life', 'light', 'like', 'line', 'little', 'live', 'lives', 'living', 'local', 'london', 'lonely', 'long', 'look', 'looking', 'looks', 'lord', 'los', 'lose', 'loses', 'losing', 'lost', 'lot', 'love', 'lover', 'loves', 'loving', 'lucy', 'machine', 'made', 'maggie', 'major', 'make', 'makes', 'making', 'male', 'man', 'manager', 'manages', 'manhattan', 'many', 'mark', 'marriage', 'married', 'marry', 'martin', 'mary', 'master', 'matt', 'max', 'may', 'means', 'meanwhile', 'medical', 'meet', 'meeting', 'meets', 'member', 'members', 'men', 'mental', 'met', 'mexico', 'michael', 'middle', 'might', 'mike', 'military', 'million', 'mind', 'miss', 'missing', 'mission', 'mob', 'modern', 'mom', 'money', 'monster', 'months', 'morning', 'mother', 'move', 'moves', 'movie', 'moving', 'mr', 'mrs', 'much', 'murder', 'murdered', 'murders', 'music', 'must', 'mysterious', 'mystery', 'name', 'named', 'nature', 'near', 'nearly', 'need', 'needs', 'neighbor', 'neighborhood', 'never', 'new', 'news', 'next', 'nick', 'night', 'north', 'nothing', 'number', 'offer', 'offers', 'office', 'officer', 'officers', 'often', 'old', 'older', 'one', 'open', 'opportunity', 'order', 'others', 'outside', 'owner', 'pair', 'parents', 'paris', 'park', 'part', 'partner', 'party', 'past', 'paul', 'pay', 'people', 'perfect', 'person', 'personal', 'pete', 'peter', 'phone', 'pilot', 'place', 'plan', 'plane', 'planet', 'plans', 'play', 'player', 'playing', 'plays', 'plot', 'point', 'police', 'political', 'poor', 'popular', 'position', 'possible', 'post', 'power', 'powerful', 'powers', 'pregnant', 'present', 'president', 'prince', 'princess', 'prison', 'private', 'problem', 'problems', 'process', 'professional', 'professor', 'project', 'protect', 'prove', 'public', 'put', 'puts', 'queen', 'quest', 'question', 'quickly', 'quite', 'race', 'radio', 'raised', 'rather', 'ray', 'ready', 'real', 'reality', 'realize', 'realizes', 'really', 'reason', 'receives', 'recently', 'red', 'refuses', 'relationship', 'relationships', 'released', 'remote', 'reporter', 'rescue', 'research', 'responsible', 'rest', 'result', 'return', 'returns', 'revenge', 'rich', 'richard', 'ride', 'right', 'rival', 'road', 'robert', 'rock', 'rocky', 'role', 'romance', 'romantic', 'room', 'rose', 'roy', 'run', 'running', 'runs', 'russian', 'sam', 'san', 'sarah', 'save', 'says', 'scene', 'scheme', 'school', 'scientist', 'scott', 'search', 'second', 'secret', 'secrets', 'security', 'see', 'seeing', 'seek', 'seeks', 'seem', 'seemingly', 'seems', 'seen', 'sees', 'self', 'sell', 'sends', 'sense', 'sent', 'serial', 'series', 'serious', 'service', 'set', 'sets', 'seven', 'several', 'sex', 'sexual', 'share', 'sheriff', 'ship', 'shop', 'short', 'shot', 'show', 'shows', 'side', 'since', 'singer', 'single', 'sister', 'situation', 'six', 'slowly', 'small', 'smith', 'social', 'society', 'soldiers', 'someone', 'something', 'somewhat', 'son', 'soon', 'south', 'space', 'special', 'spend', 'spends', 'spirit', 'stage', 'stand', 'star', 'start', 'starts', 'state', 'states', 'station', 'stay', 'steal', 'steve', 'still', 'stolen', 'stop', 'store', 'stories', 'story', 'straight', 'strange', 'stranger', 'street', 'streets', 'strong', 'struggling', 'student', 'students', 'success', 'successful', 'suddenly', 'suicide', 'summer', 'support', 'sure', 'survive', 'survivors', 'susan', 'suspect', 'system', 'take', 'taken', 'takes', 'taking', 'tale', 'talk', 'talking', 'teacher', 'team', 'ted', 'teen', 'teenage', 'teenager', 'tell', 'telling', 'tells', 'ten', 'texas', 'th', 'thing', 'things', 'think', 'thinking', 'thinks', 'thomas', 'though', 'thought', 'threatens', 'three', 'thus', 'time', 'times', 'together', 'told', 'tom', 'tommy', 'tony', 'took', 'top', 'tough', 'tour', 'toward', 'town', 'track', 'train', 'training', 'travel', 'traveling', 'travels', 'trial', 'tries', 'trip', 'trouble', 'truck', 'true', 'truly', 'trust', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'twenty', 'two', 'ultimately', 'unable', 'uncle', 'undercover', 'unfortunately', 'united', 'university', 'unknown', 'upon', 'us', 'use', 'used', 'uses', 'using', 'vacation', 'van', 'various', 'victim', 'victims', 'village', 'violence', 'violent', 'visit', 'visits', 'waiting', 'walter', 'want', 'wanted', 'wanting', 'wants', 'war', 'washington', 'watch', 'water', 'way', 'ways', 'wealthy', 'wedding', 'weekend', 'well', 'west', 'whatever', 'whether', 'white', 'whole', 'whose', 'wife', 'wild', 'william', 'win', 'winning', 'within', 'without', 'woman', 'women', 'work', 'working', 'works', 'world', 'worse', 'would', 'writer', 'writing', 'wrong', 'year', 'years', 'yet', 'york', 'young', 'younger']\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5289x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 150580 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2606x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 73787 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial multi-class / multi-label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=1234))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=None, random_state=1234))\n",
    "clf.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534141069668597"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=OneVsRestClassifier(estimator=RandomForestClassifier()),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator__bootstrap': ['True'],\n",
       "                         'estimator__max_depth': [10, 15, 20, 25],\n",
       "                         'estimator__max_features': ['auto', 'sqrt'],\n",
       "                         'estimator__min_samples_leaf': [1, 5, 7, 10],\n",
       "                         'estimator__min_samples_split': [2, 5, 7, 10],\n",
       "                         'estimator__n_estimators': [100],\n",
       "                         'estimator__random_state': [1234]},\n",
       "             refit='roc_auc_score')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hiperparameters\n",
    "n_estimators = [100]\n",
    "random_state = [1234]\n",
    "bootstrap = ['True']    \n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [10, 15, 20, 25] #  Maximum number of levels in tree[2, 5, 10, 15, 'None']\n",
    "min_samples_split = [2, 5, 7, 10] # Minimum number of samples required to split a node[2, 3, 4, 5]\n",
    "min_samples_leaf = [1, 5, 7, 10] # Minimum number of samples required at each leaf node[1, 2, 3, 4, 5]\n",
    "parameters = {\n",
    "               'estimator__n_estimators':n_estimators,\n",
    "               'estimator__random_state':random_state,\n",
    "               'estimator__bootstrap':bootstrap,\n",
    "               'estimator__max_features': max_features,\n",
    "               'estimator__max_depth': max_depth,\n",
    "               'estimator__min_samples_split': min_samples_split,\n",
    "               'estimator__min_samples_leaf': min_samples_leaf\n",
    "            }\n",
    "\n",
    "# model_to_set\n",
    "clf = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "# model_to_tune\n",
    "tuning = GridSearchCV(estimator=clf, param_grid=parameters, cv=10, n_jobs=-1, refit='roc_auc_score')\n",
    "tuning.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__bootstrap': 'True',\n",
       " 'estimator__max_depth': 25,\n",
       " 'estimator__max_features': 'auto',\n",
       " 'estimator__min_samples_leaf': 1,\n",
       " 'estimator__min_samples_split': 5,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__random_state': 1234}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "best_param = tuning.best_params_\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_1={'estimator__bootstrap': 'True',\n",
    " 'estimator__max_depth': 25,\n",
    " 'estimator__max_features': 'auto',\n",
    " 'estimator__min_samples_leaf': 1,\n",
    " 'estimator__min_samples_split': 5,\n",
    " 'estimator__n_estimators': 100,\n",
    " 'estimator__random_state': 1234}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=25,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=1234))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_model\n",
    "best_model = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, bootstrap=True, random_state=1234,\n",
    "                                                max_features=best_param_1['estimator__max_features'],\n",
    "                                                max_depth=best_param_1['estimator__max_depth'],\n",
    "                                                min_samples_split=best_param_1['estimator__min_samples_split'],\n",
    "                                                min_samples_leaf=best_param_1['estimator__min_samples_leaf']))\n",
    "best_model.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645981877617919"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC_AUC best training model\n",
    "y_pred_genres = best_model.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro',multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit over all train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=25,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=1234))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_model\n",
    "final_model = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, bootstrap=True, random_state=1234,\n",
    "                                                max_features=best_param_1['estimator__max_features'],\n",
    "                                                max_depth=best_param_1['estimator__max_depth'],\n",
    "                                                min_samples_split=best_param_1['estimator__min_samples_split'],\n",
    "                                                min_samples_leaf=best_param_1['estimator__min_samples_leaf']))\n",
    "final_model.fit(X_dtm, y_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9160934694405404"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC_AUC best training model over all train dataset\n",
    "y_pred_genres = best_model.predict_proba(X_dtm)\n",
    "roc_auc_score(y_genres, y_pred_genres, average='macro',multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precit over test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Message in a Bottle</td>\n",
       "      <td>who meets by fate ,  shall be sealed by fate ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>Midnight Express</td>\n",
       "      <td>the true story of billy hayes ,  an american c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>Primal Fear</td>\n",
       "      <td>martin vail left the chicago da ' s office to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1950</td>\n",
       "      <td>Crisis</td>\n",
       "      <td>husband and wife americans dr .  eugene and mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959</td>\n",
       "      <td>The Tingler</td>\n",
       "      <td>the coroner and scientist dr .  warren chapin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                title  \\\n",
       "1  1999  Message in a Bottle   \n",
       "4  1978     Midnight Express   \n",
       "5  1996          Primal Fear   \n",
       "6  1950               Crisis   \n",
       "7  1959          The Tingler   \n",
       "\n",
       "                                                plot  \n",
       "1  who meets by fate ,  shall be sealed by fate ....  \n",
       "4  the true story of billy hayes ,  an american c...  \n",
       "5  martin vail left the chicago da ' s office to ...  \n",
       "6  husband and wife americans dr .  eugene and mr...  \n",
       "7  the coroner and scientist dr .  warren chapin ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to predict\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074165</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.030613</td>\n",
       "      <td>0.306419</td>\n",
       "      <td>0.074120</td>\n",
       "      <td>0.047243</td>\n",
       "      <td>0.457376</td>\n",
       "      <td>0.051316</td>\n",
       "      <td>0.096894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017279</td>\n",
       "      <td>0.051738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438186</td>\n",
       "      <td>0.040845</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.141030</td>\n",
       "      <td>0.009716</td>\n",
       "      <td>0.010104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102886</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.018561</td>\n",
       "      <td>0.114983</td>\n",
       "      <td>0.288341</td>\n",
       "      <td>0.187541</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.591763</td>\n",
       "      <td>0.052061</td>\n",
       "      <td>0.046554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>0.041038</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.127028</td>\n",
       "      <td>0.037793</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.172882</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.010596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285957</td>\n",
       "      <td>0.091234</td>\n",
       "      <td>0.026353</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>0.354105</td>\n",
       "      <td>0.577770</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.664747</td>\n",
       "      <td>0.091540</td>\n",
       "      <td>0.122978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024694</td>\n",
       "      <td>0.382911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354433</td>\n",
       "      <td>0.094339</td>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.038756</td>\n",
       "      <td>0.450916</td>\n",
       "      <td>0.049033</td>\n",
       "      <td>0.025647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.151682</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.010434</td>\n",
       "      <td>0.033563</td>\n",
       "      <td>0.374941</td>\n",
       "      <td>0.120186</td>\n",
       "      <td>0.028982</td>\n",
       "      <td>0.607940</td>\n",
       "      <td>0.041877</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>0.098339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266697</td>\n",
       "      <td>0.131625</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>0.264196</td>\n",
       "      <td>0.103851</td>\n",
       "      <td>0.024671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.164812</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.045229</td>\n",
       "      <td>0.342139</td>\n",
       "      <td>0.329185</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.434833</td>\n",
       "      <td>0.126673</td>\n",
       "      <td>0.186819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.109639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162909</td>\n",
       "      <td>0.349235</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.326584</td>\n",
       "      <td>0.015336</td>\n",
       "      <td>0.017157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.074165     0.068195     0.019413     0.030613  0.306419  0.074120   \n",
       "4  0.102886     0.061214     0.018561     0.114983  0.288341  0.187541   \n",
       "5  0.285957     0.091234     0.026353     0.094958  0.354105  0.577770   \n",
       "6  0.151682     0.098810     0.010434     0.033563  0.374941  0.120186   \n",
       "7  0.158420     0.164812     0.019411     0.045229  0.342139  0.329185   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.047243  0.457376  0.051316   0.096894  ...   0.017279   0.051738   \n",
       "4       0.061513  0.591763  0.052061   0.046554  ...   0.017785   0.041038   \n",
       "5       0.037267  0.664747  0.091540   0.122978  ...   0.024694   0.382911   \n",
       "6       0.028982  0.607940  0.041877   0.056499  ...   0.080714   0.098339   \n",
       "7       0.046160  0.434833  0.126673   0.186819  ...   0.014404   0.109639   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000000   0.438186  0.040845  0.003888  0.048900    0.141030  0.009716   \n",
       "4  0.000011   0.127028  0.037793  0.008397  0.012040    0.172882  0.015622   \n",
       "5  0.000000   0.354433  0.094339  0.013204  0.038756    0.450916  0.049033   \n",
       "6  0.000000   0.266697  0.131625  0.010209  0.072155    0.264196  0.103851   \n",
       "7  0.000000   0.162909  0.349235  0.006735  0.021376    0.326584  0.015336   \n",
       "\n",
       "   p_Western  \n",
       "1   0.010104  \n",
       "4   0.010596  \n",
       "5   0.025647  \n",
       "6   0.024671  \n",
       "7   0.017157  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict over df_test\n",
    "X_test_dtm = vect.transform(df_test['plot'])\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred=final_model.predict_proba(X_test_dtm)\n",
    "y_pred=pd.DataFrame(y_pred, index=df_test.index, columns=cols)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "#y_pred.to_csv('pred_genres_text_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
