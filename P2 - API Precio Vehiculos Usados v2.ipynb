{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2 - API Precio Vehículos Usados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborado por GRUPO 1:\n",
    "- Juanita Piraban Barbosa - 201216313\n",
    "- Lorena Morales Rodríguez - 202027957\n",
    "- Alejandro Barinas Guio - 201628859\n",
    "- Jaime Humberto Trujillo Perea - 201920366\n",
    "- Alexander Zapata Galindo - 201425426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import sys\n",
    "import plotly as pt\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "#conda install py-xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from pandas import DatetimeIndex\n",
    "from pandas import Series\n",
    "from tabulate import tabulate\n",
    "from pandas import DataFrame\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "from prophet.diagnostics import cross_validation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo 'datos.csv'\n",
    "data = pd.read_csv(\"DataSet/dataTraincarListings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.2 Million listings scraped from TrueCar.com - Price, Mileage, Make, Model dataset from Kaggle\n",
    "- Each observation represents the price of an used car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', y='Price', x='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Mileage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', y='Price', x='Mileage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['State'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', y='Price', x='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Make'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', y='Price', x='Make')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Model'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', y='Price', x='Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise P2.1 (50%)\n",
    "\n",
    "Develop a machine learning model that predicts the price of the of car using as an input ['Year', 'Mileage', 'State', 'Make', 'Model']\n",
    "\n",
    "#### Evaluation:\n",
    "- 25% - Performance of the models using a manually implemented K-Fold (K=10) cross-validation\n",
    "- 25% - Notebook explaining the process for selecting the best model. You must specify how the calibration of each of the parameters is done and how these change the performance of the model. It is expected that a clear comparison will be made of all implemented models.. Present the most relevant conslusions about the whole process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desarrollo:\n",
    "Para predecir el precio de los vehículos usados, a continuación se entrenan los siguientes modelos:\n",
    "- Linear Regression\n",
    "- Bagging - Linear Regression\n",
    "- Bagging - Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Ensemble (Decision Tree, Random Forest, XGBoost)\n",
    "- Stacking (Decision Tree, Random Forest, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = data[['Year', 'Mileage','State','Make','Model']]\n",
    "y = data['Price']\n",
    "\n",
    "# Dummies\n",
    "dum = pd.get_dummies(data[['State','Make','Model']],drop_first=True)\n",
    "X_dum = pd.concat([X, dum], axis=1)\n",
    "X_dum.drop(['State','Make','Model'], inplace=True, axis=1)\n",
    "\n",
    "# Train/test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.20,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Regresión Lineal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection\n",
    "a = len(X_train.filter(like='Year', axis=1).columns)\n",
    "b = len(X_train.filter(like='Mileage', axis=1).columns)\n",
    "c = len(X_train.filter(like='State', axis=1).columns)\n",
    "d = len(X_train.filter(like='Make', axis=1).columns)\n",
    "e = len(X_train.filter(like='Model', axis=1).columns)\n",
    "\n",
    "print('Features','RMSE')\n",
    "\n",
    "# Year\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a])\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a])\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Mileage\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b])\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b])\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Mileage',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Mileage, State\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c])\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c])\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Mileage/State',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Mileage, State, Make\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d])\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d])\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Mileage/State/Make',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Mileage, State, Make, Model (all)\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e])\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e])\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Mileage/State/Make/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, State\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c]).drop(columns=['Mileage'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c]).drop(columns=['Mileage'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/State',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, State, Make\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d]).drop(columns=['Mileage'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d]).drop(columns=['Mileage'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/State/Make',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, State, Make, Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Mileage'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Mileage'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/State/Make/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Make\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d]).drop(columns=['Mileage'],axis=1)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d]).drop(columns=['Mileage'],axis=1)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Make',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Make, Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Mileage'],axis=1)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Mileage'],axis=1)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Make/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Mileage'],axis=1)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('Make')], axis=1, inplace=True)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Mileage'],axis=1)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('Make')], axis=1, inplace=True)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Year/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Mileage\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b]).drop(columns=['Year'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b]).drop(columns=['Year'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Mileage',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Mileage, State\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c]).drop(columns=['Year'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c]).drop(columns=['Year'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Mileage/State',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Mileage, State, Make\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d]).drop(columns=['Year'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d]).drop(columns=['Year'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Mileage/State/Make',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Mileage, State, Make, Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Year'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Year'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Mileage/State/Make/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# State\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c]).drop(columns=['Year','Mileage'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('State',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# State, Make\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d]).drop(columns=['Year','Mileage'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('State/Make',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# State, Make, Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Year','Mileage'],axis=1)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('State/Make/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Make\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Make',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Year, Make, Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Make/Model',np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "# Model\n",
    "X_train_1 = pd.DataFrame(X_train.iloc[:,0:a+b+c+d+e]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_train_1.drop(X_train_1.columns[X_train_1.columns.str.contains('Make')], axis=1, inplace=True)\n",
    "X_test_1 = pd.DataFrame(X_test.iloc[:,0:a+b+c+d+e]).drop(columns=['Year','Mileage'],axis=1)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('State')], axis=1, inplace=True)\n",
    "X_test_1.drop(X_test_1.columns[X_test_1.columns.str.contains('Make')], axis=1, inplace=True)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train_1, y_train)\n",
    "y_pred = m.predict(X_test_1)\n",
    "print('Model',np.sqrt(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model - all features\n",
    "lr = LinearRegression()    \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# RMSE\n",
    "y_pred = lr.predict(X_test)\n",
    "mse0 = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print('mse',mse0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bagging - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance feautures\n",
    "\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "results=[]\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    results.append((i,v))\n",
    "\n",
    "# plot feature importance\n",
    "#pyplot.bar([x for x in range(len(importance))], importance)\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features = >70% of importance\n",
    "X_train1=X_train.loc[:,['Year','Mileage','Model_Silverado','Make_GMC','Model_Super','Make_Land','Make_Lexus','Model_F-1504WD','Make_BMW','Make_Mercedes-Benz','Model_Wrangler','Model_Tahoe4WD','Model_Suburban4WD','Model_Escalade','Make_Kia','Make_Ram','Model_Suburban2WD','Model_Tundra','Model_Tahoe2WD','Model_TahoeLT','Model_TerrainFWD','Model_Sierra','Model_FusionSE','Model_CorvetteCoupe','Make_Ford','Model_Grand','Model_FocusSE']]\n",
    "X_test1=X_test.loc[:,['Year','Mileage','Model_Silverado','Make_GMC','Model_Super','Make_Land','Make_Lexus','Model_F-1504WD','Make_BMW','Make_Mercedes-Benz','Model_Wrangler','Model_Tahoe4WD','Model_Suburban4WD','Model_Escalade','Make_Kia','Make_Ram','Model_Suburban2WD','Model_Tundra','Model_Tahoe2WD','Model_TahoeLT','Model_TerrainFWD','Model_Sierra','Model_FusionSE','Model_CorvetteCoupe','Make_Ford','Model_Grand','Model_FocusSE']]\n",
    "\n",
    "# Features = >80% of importance\n",
    "#X_train1=X_train.loc[:,['Year','Mileage','Model_Silverado','Make_GMC','Model_Super','Make_Land','Make_Lexus','Model_F-1504WD','Make_BMW','Make_Mercedes-Benz','Model_Wrangler','Model_Tahoe4WD','Model_Suburban4WD','Model_Escalade','Make_Kia','Make_Ram','Model_Suburban2WD','Model_Tundra','Model_Tahoe2WD','Model_TahoeLT','Model_TerrainFWD','Model_Sierra','Model_FusionSE','Model_CorvetteCoupe','Make_Ford','Model_Grand','Model_FocusSE','Make_Porsche','Make_Dodge','Model_25004WD','Make_Cadillac','Make_Volkswagen','Model_F-150Lariat','Model_F-250Lariat','Model_CorollaLE','Model_CruzeSedan','Make_Lincoln','Model_EscapeSE','Make_Nissan','Model_F-150SuperCrew','Model_TerrainAWD','State_ TX','Make_Tesla','Make_Jeep','Make_Hyundai','Model_CayenneAWD','State_ FL','Model_Tacoma4WD','State_ CA','Model_3','Model_Land','Model_F-350Lariat','Model_4Runner4WD','Model_MalibuLT','Model_TundraSR5','Model_MDXAWD','Model_Yukon']]\n",
    "#X_test1=X_test.loc[:,['Year','Mileage','Model_Silverado','Make_GMC','Model_Super','Make_Land','Make_Lexus','Model_F-1504WD','Make_BMW','Make_Mercedes-Benz','Model_Wrangler','Model_Tahoe4WD','Model_Suburban4WD','Model_Escalade','Make_Kia','Make_Ram','Model_Suburban2WD','Model_Tundra','Model_Tahoe2WD','Model_TahoeLT','Model_TerrainFWD','Model_Sierra','Model_FusionSE','Model_CorvetteCoupe','Make_Ford','Model_Grand','Model_FocusSE','Make_Porsche','Make_Dodge','Model_25004WD','Make_Cadillac','Make_Volkswagen','Model_F-150Lariat','Model_F-250Lariat','Model_CorollaLE','Model_CruzeSedan','Make_Lincoln','Model_EscapeSE','Make_Nissan','Model_F-150SuperCrew','Model_TerrainAWD','State_ TX','Make_Tesla','Make_Jeep','Make_Hyundai','Model_CayenneAWD','State_ FL','Model_Tacoma4WD','State_ CA','Model_3','Model_Land','Model_F-350Lariat','Model_4Runner4WD','Model_MalibuLT','Model_TundraSR5','Model_MDXAWD','Model_Yukon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "seed = np.random.seed(123)\n",
    "n_samples = X_train1.shape[0]\n",
    "n_B = 100\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "\n",
    "# grow each tree deep\n",
    "baglr = LinearRegression()\n",
    "\n",
    "# DataFrame for storing predicted from each tree\n",
    "y_pred_all = pd.DataFrame(index=X_test1.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i in range(n_B):\n",
    "    X_train_1 = X_train1.iloc[samples[i], :]\n",
    "    y_train_1 = y_train.iloc[samples[i]]\n",
    "    baglr.fit(X_train_1, y_train_1)\n",
    "    y_pred_all[i] = baglr.predict(X_test1)\n",
    "    \n",
    "# mse\n",
    "mse1 = np.sqrt(mean_squared_error(y_pred_all.mean(axis=1), y_test))\n",
    "print('mse',mse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bagging - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "seed = np.random.seed(123)\n",
    "n_samples = X_train1.shape[0]\n",
    "n_B = 100\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "\n",
    "# grow each tree deep\n",
    "bagtree = DecisionTreeRegressor(max_depth=None, random_state=seed)\n",
    "\n",
    "# DataFrame for storing predicted from each tree\n",
    "y_pred_all = []\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i in range(n_B):\n",
    "    X_train_1 = X_train1.iloc[samples[i], :]\n",
    "    y_train_1 = y_train.iloc[samples[i]]\n",
    "    bagtree.fit(X_train_1, y_train_1)\n",
    "    y_pred_all.append(bagtree.predict(X_test1))\n",
    "    \n",
    "# mse\n",
    "y_pred = np.transpose(pd.DataFrame(y_pred_all))\n",
    "mse2 = np.sqrt(mean_squared_error(y_pred.mean(axis=1), y_test))\n",
    "print('mse',mse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "seed = np.random.seed(123)\n",
    "max_fig = X_train1.shape[1]\n",
    "n_B = 100\n",
    "\n",
    "# model\n",
    "clf = RandomForestRegressor(max_depth=None, n_estimators=n_B, max_features=max_fig, random_state=seed, n_jobs=-1)\n",
    "clf.fit(X_train1, y_train)\n",
    "y_pred = clf.predict(X_test1)\n",
    "\n",
    "# mse\n",
    "mse3 = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print('mse',mse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ensemble (Decision Tree, Random Forest, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['rf'] = RandomForestRegressor()\n",
    "    models['dt'] = DecisionTreeRegressor()\n",
    "    models['xgb'] = XGBRegressor()\n",
    "    return models\n",
    "\n",
    "## get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# train all the models\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train1, y_train)\n",
    "\n",
    "# predict test for each model\n",
    "y_pred = pd.DataFrame(index=X_test1.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test1)\n",
    "\n",
    "# evaluate each model\n",
    "print(\"mse results\")\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(mean_squared_error(y_pred[model], y_test)))\n",
    "\n",
    "# evaluate the mean of the predictions\n",
    "mse5 = np.sqrt(mean_squared_error(y_pred.mean(axis=1), y_test))\n",
    "print(\"ens \",mse5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Stacking (Decision Tree, Random Forest, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base models\n",
    "level0 = list()\n",
    "level0.append(('rf', RandomForestRegressor()))\n",
    "level0.append(('df', DecisionTreeRegressor()))\n",
    "level0.append(('xgb', XGBRegressor()))\n",
    "\n",
    "# define meta learner model\n",
    "level1 = LinearRegression()\n",
    "\n",
    "# define the stacking ensemble\n",
    "stk = StackingRegressor(estimators=level0, final_estimator=level1, cv=10)\n",
    "\n",
    "# fit the model on all available data\n",
    "stk.fit(X_train1, y_train)\n",
    "\n",
    "# make a prediction \n",
    "y_pred = stk.predict(X_test1)\n",
    "\n",
    "# mse\n",
    "mse6 = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(\"mse\",mse6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compración de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "table_MSE = [['Linear Regression', round(mse0,2)],['Bagging(Linear Regression)', round(mse1,2)],\n",
    "            ['Bagging(Decision Tree)', round(mse2,2)],['Random Forest', round(mse3,2)],\n",
    "             ['XGBoost', round(0,2)], ['Ensemble', round(mse5,2)],\n",
    "             ['Stacking', round(mse6,2)]]\n",
    "headers = ['Modelo', 'MSE ']\n",
    "print(tabulate(table_MSE,headers,stralign=\"decimal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final Seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LinearRegression()    \n",
    "final_model.fit(X_dum, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Price of Car\n",
      "year: 2019\n",
      "mileage: 85000\n",
      "state: TX\n",
      "make: BMW\n",
      "model: 3\n",
      "forecast price: [29340.59826589]\n"
     ]
    }
   ],
   "source": [
    "# input \n",
    "year=2019\n",
    "mileage=85000\n",
    "state='TX'\n",
    "make='BMW'\n",
    "model='3'\n",
    "\n",
    "# list\n",
    "list_all = X_dum.columns\n",
    "\n",
    "# parameters\n",
    "forecast = pd.DataFrame(np.zeros((1,613)),columns=list_all)  \n",
    "forecast['Year'] = year\n",
    "forecast['Mileage'] = mileage    \n",
    "state_ = 'State_ ' + state\n",
    "forecast['%s'%state_] = 1 \n",
    "make_ = 'Make_' + make\n",
    "forecast['%s'%make_] = 1    \n",
    "model_ = 'Model_' + model\n",
    "forecast['%s'%model_] = 1\n",
    "\n",
    "# forecast\n",
    "print('Estimated Price of Car')\n",
    "print('year:',year)\n",
    "print('mileage:',mileage)\n",
    "print('state:',state)\n",
    "print('make:',make)\n",
    "print('model:',model)\n",
    "print('forecast price:',final_model.predict(forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise P2.2 (50%)\n",
    "Create an API of the model.\n",
    "\n",
    "#### Evaluation:\n",
    "- 40% - API hosted on a cloud service\n",
    "- 10% - Show screenshots of the model doing the predictions on the local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desarrollo:\n",
    "Para desarrollar la API se siguieron los siguientes pasos:\n",
    "- Compilar modelo final (archivo *.pkl)\n",
    "- Probar modelo en batch\n",
    "- Crear API\n",
    "- Ejecutar API\n",
    "- Probar API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilar modelo final (archivo *pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_model, open('API/phishing_clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar modelo en batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from API.m09_model_deployment import predict_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_price(year,mileage,state,make,model)\n",
    "predict_price(2019,85000,'TX','BMW','3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "from API.m09_model_deployment import predict_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['GET'])\n",
    "def URLpredict():\n",
    "    return {\n",
    "         \"Price of Car\": predict_price(request.args.get('URL'))\n",
    "        }, 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(debug=True, use_reloader=False, host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check API - Local Host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:5000/predict?URL=2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check API - Amazon Web Service (AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iniciar sesión en AWS\n",
    "2. Inicializar/Reiniciar la instancia\n",
    "3. Conectar a la instancia\n",
    "4. Ejecutar la API\n",
    "5. Validar funcionamiento en link: http://ec2-18-222-147-200.us-east-2.compute.amazonaws.com:8888/predict?URL=2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
