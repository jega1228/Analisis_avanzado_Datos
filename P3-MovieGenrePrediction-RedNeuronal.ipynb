{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 - Movie Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborado por GRUPO 1:\n",
    "\n",
    "- Juanita Piraban Barbosa - 201216313\n",
    "- Lorena Morales Rodríguez - 202027957\n",
    "- Alejandro Barinas Guio - 201628859\n",
    "- Jaime Humberto Trujillo Perea - 201920366\n",
    "- Alexander Zapata Galindo - 201425426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Classify a movie genre based on its plot.\n",
    "Source: https://www.kaggle.com/c/miia4201-202019-p3-moviegenreclassification/overview\n",
    "\n",
    "- Input: movie plot\n",
    "- Output: Probability of the movie belong to each genre\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "- 20% API\n",
    "- 30% Report with all the details of the solution, the analysis and the conclusions. The report cannot exceed 10 pages, must be send in PDF format and must be self-contained.\n",
    "- 50% Performance in the Kaggle competition (The grade for each group will be proportional to the ranking it occupies in the competition. The group in the first place will obtain 5 points, for each position below, 0.25 points will be subtracted, that is: first place: 5 points, second: 4.75 points, third place: 4.50 points ... eleventh place: 2.50 points, twelfth place: 2.25 points).\n",
    "\n",
    "• The project must be carried out in the groups assigned for module 4.\n",
    "• Use clear and rigorous procedures.\n",
    "• The delivery of the project is on July 12, 2020, 11:59 pm, through Sicua + (Upload: the API and the report in PDF format).\n",
    "• No projects will be received after the delivery time or by any other means than the one established. \n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "We thank Professor Fabio Gonzalez, Ph.D. and his student John Arevalo for providing this dataset.\n",
    "See https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "#pip install livelossplot\n",
    "from livelossplot import PlotLossesKeras\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DataSet/dataTraining.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3eb27b6416b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataSet/dataTraining.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset/dataTesting.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DataSet/dataTraining.csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('DataSet/dataTraining.csv', encoding='UTF-8', index_col=0)\n",
    "df_test = pd.read_csv('Dataset/dataTesting.csv', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rating'] = df_train['rating'].astype(int)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create count vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7895, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "vect = CountVectorizer(max_features=1000 , stop_words=english_stopwords, ngram_range=(1, 1))\n",
    "X_dtm = vect.fit_transform(df_train['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'about', 'accepts', 'accident', 'accidentally', 'across', 'act', 'action', 'actor', 'actress', 'actually', 'adam', 'adult', 'adventure', 'affair', 'after', 'again', 'against', 'age', 'agent', 'ago', 'agrees', 'air', 'alan', 'alex', 'alice', 'alien', 'alive', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'america', 'american', 'among', 'an', 'and', 'angeles', 'ann', 'anna', 'another', 'any', 'anyone', 'anything', 'apartment', 'appears', 'are', 'area', 'army', 'around', 'arrested', 'arrive', 'arrives', 'art', 'artist', 'as', 'asks', 'assigned', 'assistant', 'at', 'attack', 'attempt', 'attempts', 'attention', 'attracted', 'aunt', 'away', 'baby', 'back', 'bad', 'band', 'bank', 'bar', 'based', 'battle', 'be', 'beautiful', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'begin', 'begins', 'behavior', 'behind', 'being', 'believe', 'believes', 'beloved', 'ben', 'best', 'better', 'between', 'beyond', 'big', 'bill', 'billy', 'birthday', 'black', 'blood', 'blue', 'board', 'boat', 'bob', 'bobby', 'body', 'bond', 'book', 'born', 'boss', 'both', 'boy', 'boyfriend', 'boys', 'break', 'breaks', 'bring', 'brings', 'british', 'brother', 'brothers', 'brought', 'buddy', 'building', 'business', 'but', 'buy', 'by', 'california', 'call', 'called', 'calls', 'camp', 'can', 'cannot', 'captain', 'car', 'care', 'career', 'case', 'cat', 'caught', 'cause', 'century', 'chance', 'change', 'changes', 'characters', 'charles', 'charlie', 'chicago', 'chief', 'child', 'childhood', 'children', 'chris', 'christmas', 'cia', 'city', 'class', 'clear', 'close', 'club', 'co', 'coach', 'cold', 'college', 'colonel', 'come', 'comedy', 'comes', 'coming', 'community', 'company', 'computer', 'contact', 'control', 'convince', 'convinces', 'cop', 'corrupt', 'could', 'country', 'couple', 'course', 'court', 'crash', 'crew', 'crime', 'criminal', 'cross', 'current', 'dance', 'danger', 'dangerous', 'daniel', 'danny', 'dark', 'date', 'daughter', 'dave', 'david', 'day', 'days', 'de', 'dead', 'deadly', 'deal', 'dealer', 'death', 'decide', 'decides', 'deep', 'department', 'desert', 'desperate', 'despite', 'destroy', 'detective', 'determined', 'did', 'die', 'died', 'dies', 'different', 'difficult', 'director', 'discover', 'discovers', 'do', 'doctor', 'documentary', 'does', 'doesn', 'dog', 'doing', 'don', 'door', 'down', 'dr', 'dream', 'dreams', 'drive', 'driver', 'drug', 'drugs', 'due', 'during', 'dying', 'each', 'early', 'earth', 'easy', 'ed', 'eddie', 'either', 'elizabeth', 'ellen', 'else', 'encounter', 'end', 'ends', 'enemy', 'england', 'english', 'enough', 'enter', 'entire', 'escape', 'escapes', 'especially', 'estate', 'eve', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evidence', 'evil', 'ex', 'experience', 'eye', 'eyes', 'face', 'fact', 'fall', 'falling', 'falls', 'family', 'famous', 'far', 'farm', 'fate', 'father', 'fbi', 'feel', 'feelings', 'feels', 'fellow', 'female', 'few', 'fiancee', 'fight', 'fighting', 'figure', 'film', 'final', 'finally', 'find', 'finding', 'finds', 'fire', 'first', 'five', 'flight', 'follow', 'following', 'follows', 'food', 'football', 'for', 'force', 'forced', 'forces', 'forever', 'form', 'former', 'fortune', 'found', 'four', 'francisco', 'frank', 'free', 'french', 'friend', 'friends', 'friendship', 'from', 'front', 'full', 'further', 'future', 'game', 'gang', 'gay', 'general', 'george', 'german', 'get', 'gets', 'getting', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'go', 'goal', 'god', 'goes', 'going', 'gold', 'good', 'got', 'government', 'great', 'group', 'guy', 'had', 'half', 'hand', 'hands', 'happened', 'happens', 'happy', 'hard', 'harry', 'has', 'have', 'having', 'he', 'head', 'heads', 'heart', 'helen', 'hell', 'help', 'helps', 'henry', 'her', 'hero', 'herself', 'hidden', 'high', 'him', 'himself', 'hired', 'hires', 'his', 'history', 'hit', 'hold', 'hollywood', 'home', 'hope', 'hopes', 'hospital', 'hotel', 'hours', 'house', 'how', 'however', 'huge', 'human', 'hunter', 'husband', 'idea', 'identity', 'if', 'immediately', 'important', 'in', 'includes', 'including', 'information', 'innocent', 'inside', 'instead', 'interest', 'into', 'investigate', 'investigation', 'invites', 'involved', 'is', 'island', 'isn', 'issues', 'it', 'its', 'jack', 'jail', 'jake', 'james', 'jane', 'japanese', 'jeff', 'jerry', 'jim', 'jimmy', 'job', 'joe', 'john', 'johnny', 'join', 'joins', 'journey', 'just', 'kate', 'keep', 'keeps', 'kid', 'kidnapped', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'king', 'know', 'knowing', 'known', 'knows', 'la', 'lady', 'land', 'large', 'largely', 'larry', 'last', 'late', 'later', 'latest', 'law', 'lawyer', 'lead', 'leader', 'leading', 'leads', 'learn', 'learns', 'leave', 'leaves', 'leaving', 'led', 'lee', 'left', 'less', 'let', 'life', 'light', 'like', 'line', 'little', 'live', 'lives', 'living', 'll', 'local', 'london', 'lonely', 'long', 'look', 'looking', 'looks', 'lord', 'los', 'lose', 'loses', 'lost', 'lot', 'love', 'lover', 'loves', 'lucy', 'made', 'maggie', 'major', 'make', 'makes', 'making', 'man', 'manager', 'many', 'mark', 'marriage', 'married', 'marry', 'martin', 'mary', 'master', 'matt', 'max', 'may', 'means', 'meanwhile', 'meet', 'meeting', 'meets', 'member', 'members', 'men', 'mental', 'met', 'mexico', 'michael', 'middle', 'might', 'mike', 'military', 'million', 'mind', 'miss', 'missing', 'mission', 'mob', 'money', 'months', 'more', 'morning', 'most', 'mother', 'move', 'moves', 'movie', 'mr', 'mrs', 'much', 'murder', 'murdered', 'murders', 'music', 'must', 'mysterious', 'name', 'named', 'nature', 'near', 'need', 'needs', 'neighbor', 'neighborhood', 'never', 'new', 'news', 'next', 'nick', 'night', 'no', 'north', 'not', 'nothing', 'now', 'number', 'of', 'off', 'offer', 'offers', 'office', 'officer', 'often', 'old', 'older', 'on', 'once', 'one', 'only', 'open', 'opportunity', 'or', 'order', 'other', 'others', 'our', 'out', 'outside', 'over', 'own', 'owner', 'parents', 'paris', 'park', 'part', 'partner', 'party', 'past', 'paul', 'pay', 'people', 'perfect', 'person', 'personal', 'pete', 'peter', 'place', 'plan', 'plane', 'planet', 'plans', 'play', 'player', 'playing', 'plays', 'plot', 'point', 'police', 'political', 'popular', 'position', 'possible', 'power', 'powerful', 'powers', 'pregnant', 'present', 'president', 'prince', 'princess', 'prison', 'private', 'problem', 'problems', 'process', 'professional', 'professor', 'project', 'protect', 'prove', 'public', 'put', 'puts', 'queen', 'quest', 'question', 'quickly', 'quite', 'race', 'raised', 'rather', 'ray', 're', 'real', 'reality', 'realize', 'realizes', 'really', 'reason', 'receives', 'recently', 'red', 'refuses', 'relationship', 'relationships', 'released', 'remote', 'reporter', 'rescue', 'research', 'responsible', 'rest', 'result', 'return', 'returns', 'revenge', 'rich', 'richard', 'ride', 'right', 'rival', 'road', 'robert', 'rock', 'rocky', 'role', 'romance', 'romantic', 'room', 'rose', 'roy', 'run', 'running', 'runs', 'russian', 'sam', 'same', 'san', 'sarah', 'save', 'says', 'scene', 'school', 'scientist', 'scott', 'search', 'second', 'secret', 'secrets', 'security', 'see', 'seeing', 'seeks', 'seem', 'seemingly', 'seems', 'seen', 'sees', 'self', 'sell', 'sends', 'sent', 'series', 'service', 'set', 'sets', 'seven', 'several', 'sex', 'sexual', 'share', 'she', 'sheriff', 'ship', 'short', 'shot', 'should', 'show', 'shows', 'side', 'since', 'singer', 'single', 'sister', 'situation', 'six', 'slowly', 'small', 'so', 'social', 'society', 'soldiers', 'some', 'someone', 'something', 'son', 'soon', 'south', 'space', 'special', 'spend', 'spirit', 'stage', 'stand', 'star', 'start', 'starts', 'state', 'states', 'station', 'stay', 'steal', 'steve', 'still', 'stolen', 'stop', 'store', 'stories', 'story', 'strange', 'stranger', 'street', 'streets', 'struggling', 'student', 'students', 'success', 'successful', 'such', 'suddenly', 'suicide', 'summer', 'support', 'sure', 'survive', 'survivors', 'susan', 'suspect', 'system', 'take', 'taken', 'takes', 'taking', 'tale', 'talk', 'teacher', 'team', 'ted', 'teen', 'teenage', 'teenager', 'tell', 'telling', 'tells', 'ten', 'texas', 'th', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'there', 'these', 'they', 'thing', 'things', 'think', 'thinks', 'this', 'those', 'though', 'thought', 'three', 'through', 'thus', 'time', 'times', 'to', 'together', 'told', 'tom', 'tommy', 'tony', 'too', 'took', 'top', 'tough', 'toward', 'town', 'track', 'train', 'travel', 'traveling', 'travels', 'trial', 'tries', 'trip', 'trouble', 'true', 'truly', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'twenty', 'two', 'ultimately', 'uncle', 'under', 'unfortunately', 'united', 'university', 'unknown', 'until', 'up', 'upon', 'us', 'use', 'used', 'uses', 'using', 'vacation', 'very', 'village', 'violence', 'violent', 'visit', 'walter', 'want', 'wanted', 'wants', 'war', 'was', 'water', 'way', 'ways', 'we', 'wealthy', 'wedding', 'weekend', 'well', 'were', 'west', 'what', 'whatever', 'when', 'where', 'whether', 'which', 'while', 'white', 'who', 'whole', 'whom', 'whose', 'why', 'wife', 'wild', 'will', 'william', 'win', 'winning', 'with', 'within', 'without', 'woman', 'women', 'won', 'work', 'working', 'works', 'world', 'worse', 'would', 'writer', 'writing', 'wrong', 'year', 'years', 'yet', 'york', 'you', 'young', 'younger']\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['genres'] = df_train['genres'].map(lambda x: eval(x))\n",
    "\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(df_train['genres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5289x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 267819 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2606x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 130363 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multi-class multi-label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_genres = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764422401477475"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(df_test['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = clf.predict_proba(X_test_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(y_pred_test_genres, index=df_test.index, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.123756</td>\n",
       "      <td>0.103867</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>0.366989</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.038821</td>\n",
       "      <td>0.516515</td>\n",
       "      <td>0.071927</td>\n",
       "      <td>0.104363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.065428</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.359025</td>\n",
       "      <td>0.052039</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.018552</td>\n",
       "      <td>0.183363</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.020424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129210</td>\n",
       "      <td>0.089728</td>\n",
       "      <td>0.023649</td>\n",
       "      <td>0.083562</td>\n",
       "      <td>0.357282</td>\n",
       "      <td>0.199651</td>\n",
       "      <td>0.092806</td>\n",
       "      <td>0.512687</td>\n",
       "      <td>0.063970</td>\n",
       "      <td>0.067027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024091</td>\n",
       "      <td>0.060564</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.144207</td>\n",
       "      <td>0.059189</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.019936</td>\n",
       "      <td>0.208792</td>\n",
       "      <td>0.041162</td>\n",
       "      <td>0.019134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.202882</td>\n",
       "      <td>0.139104</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.346519</td>\n",
       "      <td>0.484273</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>0.579468</td>\n",
       "      <td>0.066952</td>\n",
       "      <td>0.111810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.111593</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.046793</td>\n",
       "      <td>0.473437</td>\n",
       "      <td>0.047256</td>\n",
       "      <td>0.036477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.156802</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.341305</td>\n",
       "      <td>0.147089</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.589117</td>\n",
       "      <td>0.066103</td>\n",
       "      <td>0.064168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109783</td>\n",
       "      <td>0.101384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200932</td>\n",
       "      <td>0.102672</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.060744</td>\n",
       "      <td>0.240969</td>\n",
       "      <td>0.089068</td>\n",
       "      <td>0.021008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.186878</td>\n",
       "      <td>0.153099</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.032572</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.250824</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.418683</td>\n",
       "      <td>0.078710</td>\n",
       "      <td>0.155671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022231</td>\n",
       "      <td>0.088035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218954</td>\n",
       "      <td>0.246036</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.123756     0.103867     0.022934     0.029989  0.366989  0.119883   \n",
       "4  0.129210     0.089728     0.023649     0.083562  0.357282  0.199651   \n",
       "5  0.202882     0.139104     0.015613     0.065951  0.346519  0.484273   \n",
       "6  0.156802     0.115972     0.018002     0.078629  0.341305  0.147089   \n",
       "7  0.186878     0.153099     0.043560     0.032572  0.293750  0.250824   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.038821  0.516515  0.071927   0.104363  ...   0.025385   0.065428   \n",
       "4       0.092806  0.512687  0.063970   0.067027  ...   0.024091   0.060564   \n",
       "5       0.014112  0.579468  0.066952   0.111810  ...   0.022031   0.290749   \n",
       "6       0.011142  0.589117  0.066103   0.064168  ...   0.109783   0.101384   \n",
       "7       0.011410  0.418683  0.078710   0.155671  ...   0.022231   0.088035   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000011   0.359025  0.052039  0.008811  0.018552    0.183363  0.021250   \n",
       "4  0.001466   0.144207  0.059189  0.012512  0.019936    0.208792  0.041162   \n",
       "5  0.000000   0.380282  0.111593  0.001286  0.046793    0.473437  0.047256   \n",
       "6  0.000000   0.200932  0.102672  0.001218  0.060744    0.240969  0.089068   \n",
       "7  0.000000   0.218954  0.246036  0.003571  0.023050    0.256546  0.020322   \n",
       "\n",
       "   p_Western  \n",
       "1   0.020424  \n",
       "4   0.019134  \n",
       "5   0.036477  \n",
       "6   0.021008  \n",
       "7   0.016667  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.io.formats.csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2dfc2f5c73f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pred_genres_text_RF.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3477\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3479\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3480\u001b[0m         )\n\u001b[0;32m   3481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomma\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mseparated\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \"\"\"\n\u001b[1;32m-> 1078\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsvs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCSVFormatter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.io.formats.csvs'"
     ]
    }
   ],
   "source": [
    "res.to_csv('pred_genres_text_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el vocabulario\n",
    "X= df_train['plot'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For vocabulary only the intersec characters is used to avoid issues with data collection\n",
    "voc = set(''.join(X))\n",
    "vocabulary = {x: idx + 1 for idx, x in enumerate(set(voc))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 1,\n",
       " '1': 2,\n",
       " 'c': 3,\n",
       " 'p': 4,\n",
       " 'w': 5,\n",
       " 'k': 6,\n",
       " 'z': 7,\n",
       " ' ': 8,\n",
       " '2': 9,\n",
       " ';': 10,\n",
       " 'j': 11,\n",
       " '!': 12,\n",
       " \"'\": 13,\n",
       " ':': 14,\n",
       " '\"': 15,\n",
       " 'v': 16,\n",
       " 'n': 17,\n",
       " 'l': 18,\n",
       " 'e': 19,\n",
       " '.': 20,\n",
       " 'x': 21,\n",
       " 'q': 22,\n",
       " 'o': 23,\n",
       " 'f': 24,\n",
       " '%': 25,\n",
       " '/': 26,\n",
       " '(': 27,\n",
       " '-': 28,\n",
       " 'm': 29,\n",
       " '$': 30,\n",
       " 'h': 31,\n",
       " ',': 32,\n",
       " 't': 33,\n",
       " '=': 34,\n",
       " 'u': 35,\n",
       " 'i': 36,\n",
       " 'g': 37,\n",
       " 'b': 38,\n",
       " '&': 39,\n",
       " '?': 40,\n",
       " 'd': 41,\n",
       " 'y': 42,\n",
       " 's': 43,\n",
       " ')': 44,\n",
       " 'a': 45}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max len\n",
    "max_plot_len = 10000\n",
    "X = [x[:max_plot_len] for x in X]\n",
    "# Convert characters to int and pad\n",
    "X = [[vocabulary[x1] for x1 in x if x1 in vocabulary.keys()] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33,\n",
       " 5,\n",
       " 23,\n",
       " 8,\n",
       " 41,\n",
       " 1,\n",
       " 36,\n",
       " 24,\n",
       " 33,\n",
       " 19,\n",
       " 1,\n",
       " 43,\n",
       " 8,\n",
       " 45,\n",
       " 1,\n",
       " 19,\n",
       " 8,\n",
       " 4,\n",
       " 45,\n",
       " 43,\n",
       " 43,\n",
       " 36,\n",
       " 17,\n",
       " 37,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 1,\n",
       " 23,\n",
       " 35,\n",
       " 37,\n",
       " 31,\n",
       " 8,\n",
       " 45,\n",
       " 8,\n",
       " 5,\n",
       " 19,\n",
       " 43,\n",
       " 33,\n",
       " 19,\n",
       " 1,\n",
       " 17,\n",
       " 8,\n",
       " 33,\n",
       " 23,\n",
       " 5,\n",
       " 17,\n",
       " 8,\n",
       " 32,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 31,\n",
       " 19,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 19,\n",
       " 5,\n",
       " 43,\n",
       " 8,\n",
       " 3,\n",
       " 23,\n",
       " 29,\n",
       " 19,\n",
       " 43,\n",
       " 8,\n",
       " 36,\n",
       " 17,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 45,\n",
       " 33,\n",
       " 8,\n",
       " 45,\n",
       " 8,\n",
       " 18,\n",
       " 23,\n",
       " 3,\n",
       " 45,\n",
       " 18,\n",
       " 8,\n",
       " 24,\n",
       " 45,\n",
       " 1,\n",
       " 29,\n",
       " 19,\n",
       " 1,\n",
       " 8,\n",
       " 31,\n",
       " 45,\n",
       " 43,\n",
       " 8,\n",
       " 38,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 8,\n",
       " 29,\n",
       " 35,\n",
       " 1,\n",
       " 41,\n",
       " 19,\n",
       " 1,\n",
       " 19,\n",
       " 41,\n",
       " 8,\n",
       " 45,\n",
       " 17,\n",
       " 41,\n",
       " 8,\n",
       " 31,\n",
       " 36,\n",
       " 43,\n",
       " 8,\n",
       " 3,\n",
       " 45,\n",
       " 33,\n",
       " 33,\n",
       " 18,\n",
       " 19,\n",
       " 8,\n",
       " 43,\n",
       " 33,\n",
       " 23,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 8,\n",
       " 20,\n",
       " 8,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 8,\n",
       " 33,\n",
       " 23,\n",
       " 5,\n",
       " 17,\n",
       " 43,\n",
       " 4,\n",
       " 19,\n",
       " 23,\n",
       " 4,\n",
       " 18,\n",
       " 19,\n",
       " 8,\n",
       " 32,\n",
       " 8,\n",
       " 8,\n",
       " 11,\n",
       " 23,\n",
       " 36,\n",
       " 17,\n",
       " 19,\n",
       " 41,\n",
       " 8,\n",
       " 38,\n",
       " 42,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 8,\n",
       " 41,\n",
       " 1,\n",
       " 36,\n",
       " 24,\n",
       " 33,\n",
       " 19,\n",
       " 1,\n",
       " 43,\n",
       " 8,\n",
       " 32,\n",
       " 8,\n",
       " 8,\n",
       " 24,\n",
       " 23,\n",
       " 1,\n",
       " 29,\n",
       " 8,\n",
       " 45,\n",
       " 8,\n",
       " 4,\n",
       " 23,\n",
       " 43,\n",
       " 43,\n",
       " 19,\n",
       " 8,\n",
       " 33,\n",
       " 23,\n",
       " 8,\n",
       " 3,\n",
       " 45,\n",
       " 33,\n",
       " 3,\n",
       " 31,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 8,\n",
       " 4,\n",
       " 19,\n",
       " 1,\n",
       " 4,\n",
       " 19,\n",
       " 33,\n",
       " 1,\n",
       " 45,\n",
       " 33,\n",
       " 23,\n",
       " 1,\n",
       " 43,\n",
       " 8,\n",
       " 20,\n",
       " 8,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 42,\n",
       " 8,\n",
       " 24,\n",
       " 36,\n",
       " 17,\n",
       " 41,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 1,\n",
       " 19,\n",
       " 19,\n",
       " 8,\n",
       " 29,\n",
       " 19,\n",
       " 17,\n",
       " 8,\n",
       " 36,\n",
       " 17,\n",
       " 8,\n",
       " 4,\n",
       " 23,\n",
       " 43,\n",
       " 43,\n",
       " 19,\n",
       " 43,\n",
       " 43,\n",
       " 36,\n",
       " 23,\n",
       " 17,\n",
       " 8,\n",
       " 23,\n",
       " 24,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 8,\n",
       " 3,\n",
       " 45,\n",
       " 33,\n",
       " 33,\n",
       " 18,\n",
       " 19,\n",
       " 8,\n",
       " 32,\n",
       " 8,\n",
       " 8,\n",
       " 45,\n",
       " 17,\n",
       " 41,\n",
       " 8,\n",
       " 45,\n",
       " 1,\n",
       " 19,\n",
       " 8,\n",
       " 41,\n",
       " 19,\n",
       " 33,\n",
       " 19,\n",
       " 1,\n",
       " 29,\n",
       " 36,\n",
       " 17,\n",
       " 19,\n",
       " 41,\n",
       " 8,\n",
       " 33,\n",
       " 23,\n",
       " 8,\n",
       " 43,\n",
       " 19,\n",
       " 19,\n",
       " 8,\n",
       " 11,\n",
       " 35,\n",
       " 43,\n",
       " 33,\n",
       " 36,\n",
       " 3,\n",
       " 19,\n",
       " 8,\n",
       " 41,\n",
       " 23,\n",
       " 17,\n",
       " 19,\n",
       " 8,\n",
       " 23,\n",
       " 17,\n",
       " 8,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 8,\n",
       " 43,\n",
       " 4,\n",
       " 23,\n",
       " 33,\n",
       " 8,\n",
       " 20]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 29,  8, 20],\n",
       "       [ 0,  0,  0, ...,  6,  8, 20],\n",
       "       [ 0,  0,  0, ...,  5,  8, 20],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 41,  8, 20],\n",
       "       [ 0,  0,  0, ..., 19,  8, 20],\n",
       "       [ 0,  0,  0, ..., 19,  8, 20]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad = sequence.pad_sequences(X, maxlen=max_plot_len)\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear la red\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_pad, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10000, 128)        5888      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 26,529\n",
      "Trainable params: 26,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vocabulary) + 1, 128, input_length=max_plot_len))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, input_dim=24, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:830 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:813 run_step  *\n        outputs = model.train_step(data)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:771 train_step  *\n        loss = self.compiled_loss(\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\losses.py:1631 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\backend.py:4827 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 24) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-645bba6cb35b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(X_train, y_train_genres, validation_data=[X_test, y_test_genres], \n\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           callbacks=[PlotLossesKeras()])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 764\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:830 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:813 run_step  *\n        outputs = model.train_step(data)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:771 train_step  *\n        loss = self.compiled_loss(\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\losses.py:1631 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\keras\\backend.py:4827 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\57310\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 24) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train_genres, validation_data=[X_test, y_test_genres], \n",
    "          batch_size=128, epochs=10, verbose=1,\n",
    "          callbacks=[PlotLossesKeras()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
