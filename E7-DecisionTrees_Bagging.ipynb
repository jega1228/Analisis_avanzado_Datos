{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E7 - Decision Trees - Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborado por GRUPO 1:\n",
    "\n",
    "- Juanita Piraban Barbosa - 201216313\n",
    "- Lorena Morales Rodríguez - 202027957\n",
    "- Alejandro Barinas Guio - 201628859\n",
    "- Jaime Humberto Trujillo Perea - 201920366\n",
    "- Alexander Zapata Galindo - 201425426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Capital Bikeshare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Capital Bikeshare dataset from Kaggle: [data](https://github.com/justmarkham/DAT8/blob/master/data/bikeshare.csv), [data dictionary](https://www.kaggle.com/c/bike-sharing-demand/data)\n",
    "- Each observation represents the bikeshare rentals initiated during a given hour of a given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>total</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather  temp   atemp  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  total  hour  \n",
       "datetime                                                                   \n",
       "2011-01-01 00:00:00        81        0.0       3          13     16     0  \n",
       "2011-01-01 01:00:00        80        0.0       8          32     40     1  \n",
       "2011-01-01 02:00:00        80        0.0       5          27     32     2  \n",
       "2011-01-01 03:00:00        75        0.0       3          10     13     3  \n",
       "2011-01-01 04:00:00        75        0.0       0           1      1     4  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data and set \"datetime\" as the index\n",
    "bikes = pd.read_csv('Dataset/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# \"count\" is a method, so it's best to rename that column\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# create \"hour\" as its own feature\n",
    "bikes['hour'] = bikes.index.hour\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>total</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-19 19:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.695</td>\n",
       "      <td>50</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>336</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-19 20:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>57</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>10</td>\n",
       "      <td>231</td>\n",
       "      <td>241</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-19 21:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>15.910</td>\n",
       "      <td>61</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-19 22:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>17.425</td>\n",
       "      <td>61</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>12</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-19 23:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>16.665</td>\n",
       "      <td>66</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather   temp   atemp  \\\n",
       "datetime                                                                   \n",
       "2012-12-19 19:00:00       4        0           1        1  15.58  19.695   \n",
       "2012-12-19 20:00:00       4        0           1        1  14.76  17.425   \n",
       "2012-12-19 21:00:00       4        0           1        1  13.94  15.910   \n",
       "2012-12-19 22:00:00       4        0           1        1  13.94  17.425   \n",
       "2012-12-19 23:00:00       4        0           1        1  13.12  16.665   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  total  hour  \n",
       "datetime                                                                   \n",
       "2012-12-19 19:00:00        50    26.0027       7         329    336    19  \n",
       "2012-12-19 20:00:00        57    15.0013      10         231    241    20  \n",
       "2012-12-19 21:00:00        61    15.0013       4         164    168    21  \n",
       "2012-12-19 22:00:00        61     6.0032      12         117    129    22  \n",
       "2012-12-19 23:00:00        66     8.9981       4          84     88    23  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **hour** ranges from 0 (midnight) through 23 (11pm)\n",
    "- **workingday** is either 0 (weekend or holiday) or 1 (non-holiday weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.1\n",
    "\n",
    "Run these two `groupby` statements and figure out what they tell you about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workingday\n",
       "0    188.506621\n",
       "1    193.011873\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean rentals for each value of \"workingday\"\n",
    "bikes.groupby('workingday').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0      55.138462\n",
       "1      33.859031\n",
       "2      22.899554\n",
       "3      11.757506\n",
       "4       6.407240\n",
       "5      19.767699\n",
       "6      76.259341\n",
       "7     213.116484\n",
       "8     362.769231\n",
       "9     221.780220\n",
       "10    175.092308\n",
       "11    210.674725\n",
       "12    256.508772\n",
       "13    257.787281\n",
       "14    243.442982\n",
       "15    254.298246\n",
       "16    316.372807\n",
       "17    468.765351\n",
       "18    430.859649\n",
       "19    315.278509\n",
       "20    228.517544\n",
       "21    173.370614\n",
       "22    133.576754\n",
       "23     89.508772\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean rentals for each value of \"hour\"\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.2\n",
    "\n",
    "Run this plotting code, and make sure you understand the output. Then, separate this plot into two separate plots conditioned on \"workingday\". (In other words, one plot should display the hourly trend for \"workingday=0\", and the other should display the hourly trend for \"workingday=1\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hour'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtsklEQVR4nO3de3zU1Z3/8ddncr9fSCB3AiTcIQkiXvBuXVBrwbZ2tVsXd9u19bKr265bbXd/vezaq3bddnW7dnux1dZLVfBeKeJ9RSGQBAh3SDJJSAJkJiH3TM7vj5nBiEnIZWa+c/k8Hw8fM/PNzHw/jMObk/M9FzHGoJRSKrzYrC5AKaWU72m4K6VUGNJwV0qpMKThrpRSYUjDXSmlwlC01QUAZGVlmeLiYqvLUEqpkLJt27ZjxpjskX4WFOFeXFzM1q1brS5DKaVCiojUjfYz7ZZRSqkwpOGulFJhSMNdKaXCkIa7UkqFIQ13pZQKQxruSikVhjTclVIqDGm4K6UmrX9wiN+9V0dX36DVpajTaLgrpSZt895W/nX9Tv7xiR0MDeneEMFEw10pNWk1dicAr+5u4YFN+y2uRg2n4a6UmrTqRifzc1L4zLICfrppPy/XNFtdkvLQcFdKTYoxhhq7g7KCdO69djHlhel89ckqdjd1WF2aQsNdKTVJ9vYe2rsHWFKQRnxMFA/feBapCdH83W+3cvxkn9XlRTwNd6XUpNQ0uvvblxakATA9NZ6Hb1xO28k+bn2skgHXkJXlRTwNd6XUpFTbncRECfNyUk4dKytM54efWcKWwyf4zvO7LKxOBcV67kqp0FPT6GB+Tipx0VEfOX5tRQG1zZ08/OYhFuSm8lfnzLSowsimLXel1IQZY6i2O1ni6ZI53ddXz+fiudl8a8Muthw6HuDqFGi4K6Umoe54N529gyzNHznco2zCT2+ooGhaIrc+Vom9vTvAFSoNd6XUhFV7LqaO1nIHSEuI4Rd/vZx+1xA3/3Yb3f26REEgabgrpSasxu4gNtrG3BkpYz5vTnYyP72hgtqjHdz1VDXG6BIFgaLhrpSasGq7k4W5qcREnTlCLp03nbtXz+fFmmYe3HwgANUp0HBXSk3Q0JBhZ6Pz1Pj28bj5otlcW5HPfa/uY+PuFj9Wp7w03JVSE3LoWBdd/S6WjHIxdSQiwvc/vYSlBWnc+fh29rV0+rFCBRruSqkJqml0ALC0IH1Cr3MvUbCcxDj3EgWO7n7fF6dO0XBXSk1Itd1JQkwUc7KTJvzanLR4/ufGs7C39/Dwm4f8UJ3y0nBXSk1Ijd3JorxUosdxMXUky4oyOKsog7f2H/NxZWo4DXel1LgNuobY1dQx5vj28bigNIudTU7au7Rrxl803JVS43awrYueAdeERsqMZGVJFsbAuwd1aQJ/0XBXSo1btd0BwJL89Cm9T1lBGilx0bx9oG3qRakRabgrpcatptFJUmwUs7MmfjF1uOgoG+fOmcbbB7Tf3V803JVS41Ztd7I4Pw2bTab8XheWZtFwooe6410+qEydTsNdKTUuA64hdjd3TLm/3euCkiwAHTXjJxruSqlx2dfSSf/gEEsmOHlpNLOykshLi+cd7ZrxCw13pdS41Ng9e6ZOYNmBsYgIF5Rm8e7B47iGdLVIXxt3uItIlIhsF5EXPI8zRWSjiOz33GYMe+49InJARPaKyCp/FK6UCqzqRicp8dHMnJbos/dcWZKFs2eAnZ714ZXvTKTlfgdQO+zx3cAmY0wpsMnzGBFZCFwPLAJWAw+JSBRKqZBWY3evBCky9YupXis9/e46asb3xhXuIlIAXA3877DDa4BHPPcfAdYOO/64MabPGHMYOACs8Em1SilL9A262HO0Y8rj20+XlRzHgtxU3taLqj433pb7A8A/A0PDjs0wxjQDeG6ne47nAw3Dnmf3HFNKhai9RzsZcBmfjZQZ7sLSLLbVtdPT7/L5e0eyM4a7iHwSaDXGbBvne470O9vHrpaIyM0islVEtra16Sw1pYJZtedi6kTWcB+vlSVZ9LuG2HJYlyLwpfG03FcCnxKRI8DjwGUi8ijQIiK5AJ7bVs/z7UDhsNcXAE2nv6kx5mFjzHJjzPLs7Owp/BGUUv5WY3eSkRhDQUaCz997RXEmsVE2HRLpY2cMd2PMPcaYAmNMMe4Lpa8ZY74APAes8zxtHbDBc/854HoRiRORWUAp8L7PK1dKBUx1o5MlBek+vZjqlRAbxfJiXQLY16Yyzv0HwBUish+4wvMYY8wu4ElgN/AKcJsxRjvTlApRvQMu9rV0+mx8+0hWlmSx52gnbZ19fjtHpJlQuBtjXjfGfNJz/7gx5nJjTKnn9sSw591rjJljjJlnjHnZ10UrpQJnd3MHriEz5TXcx3JhqXtI5LsHtfXuKzpDVSk1plMzU/0Y7ovy0khLiNEhkT6k4a6UGlO13UlWchw5qfF+O0eUTVhZ4l4C2BhdisAXNNyVUmOqaXT4fGbqSFaWZNHs7OXQMV0C2Bc03JVSo+rqG+RA60m/jG8/3YUl7iHR2jXjGxruSqlR7W7uYMj4t7/dq2haIoWZCTok0kc03JVSo/LnzNSRXFCSzXuHjjPoGjrzk9WYNNyVUqOqsTvISY1nuh8vpg53YWkWJ/sGqfJsxK0mT8NdKTUq98zUwLTaAc6bPQ0ReHu/rjMzVRruSqkRdfYOcKity68zU0+XkRTLkvw03j6giwlOlYa78jtjjE4rD0E7GzsAAtpyB/eQyO31Dk72DQb0vOFGw1353abaVs79/ibqjuv45VBS0+gAAncx1evCkiwGhwxbDmnXzFRouCu/+79D7g2Qtxw6ceYnq6BRbXeSn57AtOS4gJ532cwM4qJtuvXeFGm4K7+r9ox82N7Qbm0hakJqGp0BGd9+uviYKFbMytTJTFOk4a78atA1dKrvdnu9w9pi1Lg5uweoO94d8P52rwtLs9jfepKjzl5Lzh8ONNyVXx1oO0nPgItZWUnsbenUi2QhoqbRsxKkjzfEHq+VJe4lgHV3psnTcFd+Vd3gDom/Pm8mxkB1g8PagtS4VFt0MdVrQU4q05Jitd99CjTclV9VNzpIiYvm2op8ACrrtd89FNTYncyclkhaYowl57fZhPNLsnQJ4CnQcFd+VW13z3BMT4xlTnaS9ruHiGq707JWu9eFJVm0dfaxr+WkpXWEKg135Td9gy5qmztYWpAOwLKiDLY3OLQlFuSOn+yj0dFjyUiZ4VZ6tt7TrpnJ0XBXfrOnuZMBl6HMExIVRRmc6Oqn/kS3xZWpsXgvpi6x6GKqV356ArOzknh7vy5FMBka7spvvOPblxamA1BR5L7Vrpng5t0zdXF+qsWVuEfNbDl8gv5BXQJ4ojTcld9U2Z1kJceSl+ZeLnbujBQSY6P0omqQq250Mjs7iZR4ay6mDndBaRbd/S6263dmwjTcld9U2x0sLUg/tfdmlE0oK0jXlnuQq7E7A7oS5FjOmzMNm2i/+2RouCu/8O69efpFuWUz06lt7qCn32VRZWosrR29HO3oZYnnIrjVUuNjKCtM13CfBA135Rc7G50MGSg7LSQqCjMYHDLsbHJaU5ga06mZqRaPlBnuwpIsqhocOHsGrC4lpGi4K784tffmaSFRfuqiqvahBqNquxObwMJc6y+meq0syWLIwHu6BPCEaLgrv6iyO8hPTyDrtOVis5LjKMpMpLLOYU1hakw1jU5KpieTFBdtdSmnVBRlkBgbpatETpCGu/KLavvoy8VWFKVTWd+uk5mCjDHGMzM13epSPiI22sY5szJ1EbEJ0nBXPtfumai0dJSLcsuKMmjt7KNZl3MNKkc7ejl2si+o+tu9LijN5tCxLhodPVaXEjI03JXPVXsuypWN0XIHncwUbEa7ThIMLvAsAayzVcdPw135nHdZ38WjhMT8nFTiom16UTXIbNzdQly0LagupnrNnZHM9JQ43tR+93HTcFc+V2V3z3BMHWWGY2y0jSX5aTpTNYjUHe/i2e2N/NU5M4mPibK6nI8RES5fMIPXalvp0g1fxkXDXflctd3xsfHtp6soSmdnUwd9gzqZKRj812sHiLYJX7l4ttWljGpteR49Ay427m6xupSQoOGufOqos5fWzjNflFtWlEH/4BC1zZ0BqkyNpu54F89sb+Tz5xQxPTXe6nJGdXZxJvnpCazf0Wh1KSHhjOEuIvEi8r6IVInILhH5jud4pohsFJH9ntuMYa+5R0QOiMheEVnlzz+ACi5V3pUgz9hyd39dtN/deg9udrfab7l4jtWljMlmEz5Vnsdb+49x7GSf1eUEvfG03PuAy4wxZUA5sFpEzgXuBjYZY0qBTZ7HiMhC4HpgEbAaeEhEgq8TT/lFtd1BtE1YlDf2RbmctHhy0+J1xIzF6o9383RlIzesCO5Wu9fa8nxcQ4YXqpqsLiXonTHcjZt3n6sYz38GWAM84jn+CLDWc38N8Lgxps8Ycxg4AKzwZdEqeFXbncydkTKui3LeyUzKOg9uPkCUTbjlkuButXvNy0lhQW4q63douJ/JuPrcRSRKRHYArcBGY8wWYIYxphnAczvd8/R8oGHYy+2eY6e/580islVEtra16djVcOCd4VhWOL5x0hWFGdjbe2jt1MlMVnC32u18fkURM0Kg1e61tjyPHQ0OjhzrsrqUoDaucDfGuIwx5UABsEJEFo/xdBnpLUZ4z4eNMcuNMcuzs7PHVawKbnXHu3H2DJyxv91r2Uz383Zo14wlHtx8AFsItdq9PlWehwh6YfUMJjRaxhjjAF7H3ZfeIiK5AJ7bVs/T7EDhsJcVAPo7VAT48GLq+Frui/LSiIkStnsmPanAaTgRmq12gNy0BM6ZlcmGHU26PtEYxjNaJltE0j33E4BPAHuA54B1nqetAzZ47j8HXC8icSIyCygF3vdx3SoIVdudxEXbmDsjZVzPj4+JYmFuqo6YsYC31f6VIB8hM5prK/I5fKzr1JIJ6uPG03LPBTaLSDXwAe4+9xeAHwBXiMh+4ArPY4wxu4Angd3AK8BtxhidqRIBqu0OFuWlEhM1/l8IK4oyqGpwMujSDZADpeFEN3/cZueGswvJSQutVrvX6sW5xEbZtGtmDOMZLVNtjKkwxiw1xiw2xnzXc/y4MeZyY0yp5/bEsNfca4yZY4yZZ4x52Z9/ABUcXEOGnY0d4+5v96ooSqdnwMXeFp3MFCgPvX4Amwi3XFJidSmTlpYQw2Xzp/N8VZM2DEahM1SVTxxoPUnPgGvCy8UuOzWZyeGHqtTpGk5089RWO9evCN1Wu9fainyOneznnYO6Q9NINNyVT4x3ZurpCjISyEqO1XAPkA9b7aHZ1z7cpfOzSY2PZsN27ZoZiYa78olqu4OUuGhmZyVN6HUiQnlhBtsb9KKqv9nbP2y156YlWF3OlMVFR3HVklxe2XWU7n5dKfJ0Gu7KJ6rtThbnp2GzjTTNYWwVRekcauvC0d3vh8qU14ObD4ZNq91rbUU+3f26UuRINNzVlPUNuqht7mDpOGemnu5Uv7uOd/cbd6u9gb88Ozxa7V4rijPJS4tngy5H8DEa7mrK9jR3MuAyZ1zDfTRLC9KwiV5U9aeHXg+/Vju4V4q8pjyPN/a1cVxXivwIDXc1ZdUTnJl6uqS4aObl6GQmf/G22j93dgF56eHTave6tsK9UuSLNc1WlxJUNNzVlFXZnUxLiiV/CsFRUZTOjgYHQ0M6ndzXHnr9IAC3hvC49rHMz0llfk4K63XUzEdouKspq7Y7WFqQhsjEL6Z6VRSm09k7yMG2k2d+shq3RkfPqb72cGy1e60pz6ey3kHdcV0p0kvDXU1JV98gB1pPTnh8++mWzdTJTP7w0OYDACE9G3U81pTnAeiF1WE03NWU7Gx0MmQY9xruo5k1LYm0hBgd7+5DjY4entzawOeWF06pyywU5KW7V4pcv6NRV4r0iLa6ABXavKvyTbXlbrMJ5YXpYdFyH3QN0T3gorffRbfnv54BFz39LgaHhjhn1jQSYv2/8+R/v+5utd96aXi32r3WVuRzzzM11DQ6p/x9DAca7mpKquwO8tMTyEqOm/J7VRSl85+b9nOyb5DkuOD+alY1OPjBy3tw9gzQM+Ciu3+QHk+ID7jGbjlmJMaw7vxi1p1XTEZSrF/qa3L08MQHDVwXAa12r6sW5/KtDbtYv71Jwx0NdzVF1XbnpIdAnq6iKANj3MG5siTLJ+/pD119g9z+h0p6+ocoL0wnMTaKhJgoEmLd/yUOv3/qZ9EkxETR3T/Io+/V8cCf9/M/bxziL88u5EsXzqIgI9EntfUOuNi8p5Vfvn0YgFvDbFz7WNISY7h0fjbPVzfxzasXEDWJ2dLhRMNdTVp7Vz/1J7q5YUWRT96vvDAdgO317UEd7t97qRZ7ew9Pfvk8zi7OnPDrL5k3nX0tnfzPG4d49L06fvdeHdcszeXLF89hQW7qhN9v0DXE/x06zoYdTfxp51E6+wbJSo7l/31yoc/+0QgVa8vz+dOuFt49eIwLSyN7+04NdzVp1Y3e/nbftNzTEmIomZ4c1P3ub+1v47Et9XzpglmTCnavuTNSuP9zZXztL+byq7cP84f361m/o4lL5mXz5YvmcO7szDGHlhpj2N7g4LkdTbxQ3cyxk32kxEWzanEOa8rzOG/2NKInsGlKuLh0/nRS4qN5dnujhrvVBajQVe1ZC2Zxvm/CHdzj3TftacUYM6Vx8/7Q0TvA1/9YzZzsJP5p1TyfvGdeegL/8smF/P1lpfzuvSP8+p0j3PCL9ygrTOeWi2dzxcKcj3Qv7G/pZMOOJp6raqL+RDex0TYunz+dNeV5XDJvOvEx/r9QG8ziY6K4anEuL1Q30bPWFZAL18FKw11NWpXdyews9xBGX6koyuCpbXbqT3Qzc9rElg/2t39/YTdHO3p5+pbzfR6iaYkx3H5ZKV+6cDZ/3GbnF28d4iuPVjI7K4kvXjiLzt5BNuxoora5A5vAypIs/v6yElYtziE13neffzhYU5HHE1sb+HNtC9eU5VldjmU03NWkVdsdnD9nmk/fs6IoHYDK+vagCvfX9rTw5FY7t14yhwrPKpb+EB8TxRfOnckNK4p4eWczP3/jIN98difg/my+fc1Crl6aR3bK1EcnhatzZ00jJzWe9dsbNdyVmqijzl5aO/t8PuRs7owUkmKj2F7v4NqKAp++92Q5uvu5++ka5uekcMcnSgNyziib8MmleVy9JJcqu5PMxFiKpkXWxdHJstmENeV5/PLtw5zo6ifTT8NNg13kXXFRPuHdVm+qM1NPF2UTyoJsMtO3n9vFia5+7ruujLjowPbhuneqStdgn6A15fkMRvhKkRrualKq7Q6ibMLCXN+GO7i7H2qbO+jpd/n8vSfqlZ1HWb+jidsuLfHphWPlXwtyU5g7IzmiV4rUcFeTUm13MndGil9GI1QUZjA4ZNjZ5PT5e0/E8ZN9fPPZGhblpXL7ZZExhT9ciAhrK/LZVtdOw4luq8uxhIa7mjBjDNV2J2U+Gt9+unLvRdU6axcR+38bdtHRO8D9nysjJgLHjIe6T5V5V4qMzNa7fmPVhNWf6MbZM+C39TuykuOYOS3R0n7356uaeLGmmTs/MZf5OROfNaqsV5CRyIriTJ6pbIzITWA03NWEVdl9OzN1JBWF6VTWt1uyfGtrZy//umEnZYXpfPmi2QE/v/KdL5w3k0PHungmAvveNdzVhFU3OIiLtjEvJ8Vv56goyqC1s49mZ6/fzjESYwzfeGYnPf0u7r+uLCKn8IeTa5bmUlaYzn1/2kt3/6DV5QSUfnPVhFXbnSzMS/VrP7R3MtPb+4/57RwjeaaykT/XtnDXqnmUTE8O6LmV74kI/3r1Ao529PKLNw9bXU5AabirCXF5RrGU+Xm97EV5aSzKS+VHf9pDe1e/X8/l1ezs4dvP7+Ls4gz+ZuWsgJxT+d/y4kyuXpLLz984SEtHYH8TtJKGu5qQA60n6e53+bW/HdyTmX782TIc3QN85/ldfj0XuLtj7n66hkGX4cefLYv4tcDDzddXz8c1ZLj/1b1WlxIwGu5qQrwzUwOx081Cz/jy9TuaeHXXUb+e64kPGnhjXxt3Xzmf4qzgWdNG+UbRtERuWlnMU9vs7LJ4/kSgaLirCalqcJAcF83sAAXgrZeUMD8nhW+u34mj2z/dM/b2bv79xVrOmz2NG8+d6ZdzKOvddmkJ6Qkx3PtibURsoq3hriakst5BRVE6tgB1W8RG27jvujJOdPXz3ed3+/z9ewdc3P777Rhj+NFnlwbsz6UCLy0hhjs/MZd3Dx7ntT2tVpfjdxruatw6ewfYe7SDZX5c8nYki/PTuO2SOTyzvZFNtS0+e1/XkOHOx3dQZXdw/+fKKczUxbnC3efPKWJ2dhL3vlTLgGvI6nL86ozhLiKFIrJZRGpFZJeI3OE5nikiG0Vkv+c2Y9hr7hGRAyKyV0RW+fMPoAKnqsHJkIGzZgY23AFuv6yU+TkpfOPZGpzdAz55z++9VMsru47yL1cvZPXiHJ+8pwpuMVE2vnHlAg61dfH7LfVWl+NX42m5DwJfM8YsAM4FbhORhcDdwCZjTCmwyfMYz8+uBxYBq4GHRCRy97oKI9vq2hH5cO2XQIqNtvHjz5Zx7GQ///bi1LtnfvPOYX759mFuOr+YL16gwx4jyeULpnP+nGk88Od9OHt801AIRmcMd2NMszGm0nO/E6gF8oE1wCOepz0CrPXcXwM8bozpM8YcBg4AK3xct7LAtvp25k5PsWxbtyUFaXzlYvc2dJv3Tr7PdOPuFr77wm6uWDiDf/3kQh9WqEKBiPDNqxfg6Bngwc0HrC7HbybU5y4ixUAFsAWYYYxpBvc/AMB0z9PygYZhL7N7jp3+XjeLyFYR2drW1jaJ0lUgDQ0Ztte1s8yCLpnh/uHyUkqnJ3PP0zV09E681VXV4ODv/1DJkvw0fnp9hY5nj1CL8tL47LICfvPOEeqOd1ldjl+MO9xFJBl4GrjTGNMx1lNHOPaxcUfGmIeNMcuNMcuzs7PHW4ayyP7Wk3T2DVrS3z5cXHQU911XRmtnL/e+UDuh1zac6OaLj3xAdkoc/7vubL+sRa9Cxz+tmkeUTfjhK3usLsUvxhXuIhKDO9gfM8Y84zncIiK5np/nAt7fk+1A4bCXFwBNvilXWaWy3r22utXhDrhXa7x4Dk9sdU88Gg9n9wA3/fp9+geH+PVNK3SDacWM1Hi+cvEcXqo5ytYjJ6wux+fGM1pGgF8CtcaYnwz70XPAOs/9dcCGYcevF5E4EZkFlALv+65kZYVtde1kJsVSHCR7ed5xeSkl05O5++lqOs/QPdM36OLm322l4UQPD//1cl0QTJ3ydxfNYkZqHP/2Ym3Yrfk+npb7SuBG4DIR2eH57yrgB8AVIrIfuMLzGGPMLuBJYDfwCnCbMcb6zTDVlFTWtbOsKAP3v/XWi4+J4kefXUpLRy/fe2n0X6uNMXz9j9VsOXyCH1+3lHNnTwtglSrYJcZGc9eq+VQ1OHi+Orw6GMYzWuZtY4wYY5YaY8o9/71kjDlujLncGFPquT0x7DX3GmPmGGPmGWNe9u8fQfnbia5+Dh3rCooumeGWFWXwdxfO5g/v14+6NPBPNu5j/Y4m7lo1jzXlH7uurxSfrshncX4qP3plL70D4dMO1Rmq6oy8e5kGW7gD/OMVc5mdncTXn67mZN9HN2N48oMGfvbaAa4/u5BbL5ljUYUq2NlswjevWkijo4dfvh0+a75ruKsz2lbfTrRN/L7M72TEx0Tx488upcnZw/df+nD0zJv72rjn2RoumpvNv61dHDTdSSo4nTdnGlcsnMFDmw/Q1tlndTk+oeGuzmhbXTuL8lKJjwnOoYNnzczkiytn8diWet49cIza5g5ufayS0unJPPj5Cr/uGKXCxz1XzqdvcIifbNxndSk+od96NaYB1xBVDQ7LJy+dydf+Yh6zspK464/V/O1vPiA5Lppf/83ZpFg0m1aFntnZyXzh3Jk88UE9e492Wl3OlGm4qzHtbuqgb3AoKPvbh0uIdY+eaXL20Nk7yK9uOpvctASry1Ih5o7LS0mOi+belyY2QS4YabirMQXT5KUzObs4k4c+v4zHvnQOC/NSrS5HhaCMpFj+4fJS3tzXxtPb7FaXMyUa7mpM2+rayUuLD5lW8JVLcikrTLe6DBXCbjq/mHNmZfLN9TXUNo+10kpw03BXY6oMgsXClAqk6Cgb//X5ZaQlxPCVR7eF7LLAGu5qVE2OHpqcvSHRJaOUL2WnxPHQXy2jsb2Hrz25IySXJtBwV6MKpf52pXztrJmZfPPqBfy5tpX/fuOg1eVMmIa7GtW2unbiY2wsyNWLkyoy3XR+MZ8qy+P+V/eOusRFsNJwV6OqrGunrCBdJwGpiCUifP/TS5iTncw/PL6dJkeP1SWNm/6tVSPq6Xexq6lDL6aqiJcUF83PbzyL/sEhbnmskr7B0FhcTMNdjaja7mBwyHBWkYa7UnOyk7nvuqVUNTj4txemvkF7IGi4qxFt81xM1Za7Um6rF+fy5Ytm8+h79TxTGfwTnDTc1Ygq6xzMzkoiMynW6lKUChp3rZrHubMz+cazNexuCu4JThru6mOMMVTW6+QlpU4XHWXjZze4Jzjd8lhwT3DScFcfc+R4Nye6+nV8u1IjCJUJThru6mO2BfHOS0oFg1CY4KThrj5mW107KfHRlGQnW12KUkEr2Cc4abirj6msa2dZUQY2m25Np9RoRIQffGYJJdODc4KThrv6CGfPAPtaO1mm49uVOqPE2Gh+/oXgnOCk4a4+YkeDA2O0v12p8Zqdncx915VR1eDghy/vtbqcUzTc1Udsq2vHJlBWmGZ1KUqFjNWLc1h33kx+9c7hoOl/13BXH7G9vp15Oam6sbRSE3T3lQuYk53E157agaO73+pyNNzVh1xDhu31Ds6amW51KUqFnITYKP7z+gqOn+znG8/WYIy149813NUp+1o6Odk3qP3tSk3S4vw0vvoXc3mp5ijPVDZaWouGuzrl1OSlokyLK1EqdH35ojmsKM7kW8/touFEt2V1aLirUyrr2slKjqMwM8HqUpQKWVE24f7PlSHAV5/cgcui5Qk03NUp2+rbOWtmOiI6eUmpqSjMTOQ7axbxwZF2fm7R8gQa7gqAts4+6o53a3+7Uj5ybUU+Vy/N5T827qPG7gz4+TXcFQCV3s05dGaqUj4hIty7djFZyXHc8cR2evoDO3tVw10B7v72mChhcb5OXlLKV9ITY7n/c2Ucauviey/VBvTcGu4KcLfcF+enER8TZXUpSoWVlSVZfPGCWfzuvTo272kN2HnPGO4i8isRaRWRncOOZYrIRhHZ77nNGPaze0TkgIjsFZFV/ipc+U7/4BBVdqduhq2Un9y1ah7zZqRw1x+rOX6yLyDnHE/L/TfA6tOO3Q1sMsaUAps8jxGRhcD1wCLPax4SEW0KBrldTU76B4f0YqpSfhIfE8UD15fT0TPA3c8EZvbqGcPdGPMmcOK0w2uARzz3HwHWDjv+uDGmzxhzGDgArPBNqcpfvJOXdM9UpfxnQW4q/7x6Hht3t/DEBw1+P99k+9xnGGOaATy30z3H84HhVds9xz5GRG4Wka0isrWtrW2SZShfqKxvpyAjgRmp8VaXolRY+9uVszh/zjS++8Jujhzr8uu5fH1BdaTZLyP+/mGMedgYs9wYszw7O9vHZajxMsawra5du2SUCgCbTbjvujKibcKdT+xg0DXkv3NN8nUtIpIL4Ln1XgK2A4XDnlcANE2+POVvjY4eWjr6NNyVCpC89ATuvXYJOxoc/NfmA347z2TD/Tlgnef+OmDDsOPXi0iciMwCSoH3p1ai8qdT/e06UkapgLmmLI9rK/L52WsHTk0g9LXxDIX8A/B/wDwRsYvIF4EfAFeIyH7gCs9jjDG7gCeB3cArwG3GmODZVFB9TGVdOwkxUczPSbG6FKUiynfWLCInNZ6fbdrvl/ePPtMTjDE3jPKjy0d5/r3AvVMpSgVOZb2D8sJ0oqN0PptSgZQaH8Mjf3s2een+WYVV/0ZHsO7+QXY3d2h/u1IWKZmeQmLsGdvYk6LhHsGqGpy4hoyGu1JhSMM9gnkv5FQUpVtbiFLK5zTcI9gHR05QMj2Z9MRYq0tRSvmYhnuE2nO0gzf3tXH5/OlnfrJSKuRouEeoH768h+S4aG65ZI7VpSil/EDDPQK9e+AYm/e2cdulJdolo1SY0nCPMENDhu+9XEt+egLrzi+2uhyllJ9ouEeY56ub2NnYwT+tmqu7LikVxjTcI0jfoIsfvbKXhbmprCkbcSVmpVSY0HCPIL99t45GRw/fuGoBNttIqzMrpcKFhnuEcHT387PX9nPR3GwuKM2yuhyllJ+FdLi3d/Xzhf/dws5Gp9WlBL2HXj9IZ98g91w53+pSlFIBENLhbm/vYX9rJ2sffIefbdrv111NQlnDiW5+884RPrOsgAW5qVaXo5QKgJAO9yUFafzpzou4akku92/cx2d+/n8cbDtpdVlB5/5X9yICX71irtWlKKUCJKTDHSA9MZaf3lDBz26ooO54F1f/9C0eefcIQ0Mjbt0acXY2Olm/o4m/vWCW39aNVkoFn5APd69ryvL4050Xce7saXzruV389a/ep8nRY3VZljLG8L2XaslIjNFlBpSKMGET7gAzUuP59U1n871rl1BZ386qB97kmUo7xkRmK/6NfW28e/A4/3B5KanxMVaXo5QKoLAKdwAR4fPnFPHyHRcyb0YKX32yilsereT4yT6rSwso15Dh+y/tYea0RP7qnJlWl6OUCrCwC3evmdOSeOLL53H3lfN5bU8rqx54iz/vbrG6rIB5utLO3pZO/nnVfGKjw/Z/s1JqFGH9tz7KJnzl4jlsuH0lWcmxfOm3W/n6H6vp7B2wujS/6ul38ZNX91FWmM5VS3KsLkcpZYGwDnevBbmpbLh9JbdeMoentjWw+oG3eHqbnZN9g1aX5he/eucwRzt6+caV8xHRZQaUikQREe4AcdFR/PPq+Tz1lfOIi7HxtaeqWP7vG7n995X8eXcL/YPhMQHq+Mk+/vv1g3xiwQzOmT3N6nKUUhaJtrqAQDtrZiZ//seLqaxvZ/2ORl6sbuaF6mbSE2O4akkua8vzWT4zI2QX1vrZawfoGXBxty4zoFREi7hwB7DZhOXFmSwvzuRb1yzirf1trN/exLOVjfx+Sz356QlcU5bH2oo85ueEznT9I8e6ePS9Ov7y7EJKpidbXY5SykIRGe7DxUTZuGz+DC6bP4OuvkE27m5hw45GfvHWIX7+xkHm56SwpjyfT5XnkR/kMzx/9Kc9xEbbuPMTpVaXopSyWMSH+3BJcdGsrchnbUU+x0/28WJNMxt2NPHDV/bww1f2sKI4k2uX5XPV4lzSEoNrUlBlfTsv1RzljstLmZ4Sb3U5SimLSTDM3ly+fLnZunWr1WWMquFENxt2NPLs9kYOtnURG2XjsvnTWVuRz6Xzs4mLtna7uiZHD7c8Vkljew9v3HUJSXH6b7ZSkUBEthljlo/4Mw338TPGsKupg2cqG3muqoljJ/tIjY/m6qV5fHpZPmcVBe5CrDGGbXXt/PqdI7yy6yjGGO7/XBnXVhQE5PxKKetpuPvBoGuIdw4eZ/32Rl7ZeZSeARcFGQmsLXd36/jrgmbfoIsXqpr5zbtHqGl0khofzfUrirjx3JkUZib65ZxKqeCk4e5nXX2DvLr7KM9ub+Lt/W0MGViSn8bainyuXpJLTtrU+8BbO3p5dEs9v99Sx7GT/ZRMT+am84v59LJ8EmO1G0apSKThHkCtnb08X9XM+u2N1Hi2/5uWFMvcGSnMy0kZdptMyjhWaqxqcPDrdw7zYk0zg0OGy+ZN56aVxVxQkqWzT5WKcBruFtnf0slb+4+xr6WTvS2d7DvaSVe/69TP89MTmDsjmXk5qczLSWbujBTmZCcTZRNe3nmUX79zmO31DpLjorlueQHrziumOCvJwj+RUiqYjBXufvt9XkRWA/8JRAH/a4z5gb/OFaxKZ6RQOiPl1OOhIUOjo4d9LZ3sOdrpDv2jnbx94BgDLvc/slE2ITE2is7eQYqnJfLtaxbymbMKxtXKV0opL7+Eu4hEAQ8CVwB24AMRec4Ys9sf5wsVNptQmJlIYWYily+Ycer4gGuII8e6TrXuj3b0cuXiXC6emx2yyyAopazlr5b7CuCAMeYQgIg8DqwBIjrcRxMTZfuwlb/U6mqUUuHAX6tC5gMNwx7bPceUUkoFgL/CfaS+hI9cuRWRm0Vkq4hsbWtr81MZSikVmfwV7nagcNjjAqBp+BOMMQ8bY5YbY5ZnZ2f7qQyllIpM/gr3D4BSEZklIrHA9cBzfjqXUkqp0/jlgqoxZlBEbgf+hHso5K+MMbv8cS6llFIf57dx7saYl4CX/PX+SimlRhcxe6gqpVQk0XBXSqkwFBRry4hIG1A3hbfIAo75qJxQpp+Dm34Obvo5uIXz5zDTGDPicMOgCPepEpGtoy2eE0n0c3DTz8FNPwe3SP0ctFtGKaXCkIa7UkqFoXAJ94etLiBI6Ofgpp+Dm34ObhH5OYRFn7tSSqmPCpeWu1JKqWE03JVSKgyFdLiLyGoR2SsiB0TkbqvrsYqIHBGRGhHZISLhtxntGETkVyLSKiI7hx3LFJGNIrLfc5thZY2BMMrn8G0RafR8L3aIyFVW1hgIIlIoIptFpFZEdonIHZ7jEfedCNlwH7aV35XAQuAGEVlobVWWutQYUx6B43l/A6w+7djdwCZjTCmwyfM43P2Gj38OAP/h+V6Ue9Z7CneDwNeMMQuAc4HbPLkQcd+JkA13hm3lZ4zpB7xb+akIYox5Ezhx2uE1wCOe+48AawNZkxVG+RwijjGm2RhT6bnfCdTi3gUu4r4ToRzuupXfhwzwqohsE5GbrS4mCMwwxjSD+y87MN3ieqx0u4hUe7ptwr4rYjgRKQYqgC1E4HcilMP9jFv5RZCVxphluLuobhORi6wuSAWF/wbmAOVAM3C/pdUEkIgkA08DdxpjOqyuxwqhHO5n3MovUhhjmjy3rcCzuLusIlmLiOQCeG5bLa7HEsaYFmOMyxgzBPyCCPleiEgM7mB/zBjzjOdwxH0nQjncdSs/QESSRCTFex/4C2Dn2K8Ke88B6zz31wEbLKzFMt4w87iWCPheiIgAvwRqjTE/GfajiPtOhPQMVc/Qrgf4cCu/e62tKPBEZDbu1jq4d9b6fSR9DiLyB+AS3Mu6tgDfAtYDTwJFQD1wnTEmrC82jvI5XIK7S8YAR4Ave/udw5WIXAC8BdQAQ57D38Dd7x5Z34lQDnellFIjC+VuGaWUUqPQcFdKqTCk4a6UUmFIw10ppcKQhrtSSoUhDXcVkUSkePgKikqFGw13pXxERKKtrkEpLw13FcmiROQXnnW/XxWRBBEpF5H3PIttPetdbEtEXheR5Z77WSJyxHP/JhF5SkSeB1617o+i1EdpuKtIVgo8aIxZBDiAzwC/Bb5ujFmKe5bjt8bxPucB64wxl/mrUKUmSsNdRbLDxpgdnvvbcK+gmG6MecNz7BFgPCtsbgz3qewq9Gi4q0jWN+y+C0gf47mDfPj3Jf60n3X5sCalfELDXakPOYF2EbnQ8/hGwNuKPwKc5bn/2QDXpdSE6dV9pT5qHfBzEUkEDgF/4zl+H/CkiNwIvGZVcUqNl64KqZRSYUi7ZZRSKgxpuCulVBjScFdKqTCk4a6UUmFIw10ppcKQhrtSSoUhDXellApD/x8F6dUacncOmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean rentals for each value of \"hour\"\n",
    "bikes.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for workingday == 0 and workingday == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly rental trend for \"workingday=0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly rental trend for \"workingday=1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write about your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.3\n",
    "\n",
    "Fit a linear regression model to the entire dataset, using \"total\" as the response and \"hour\" and \"workingday\" as the only features. Then, print the coefficients and interpret them. What are the limitations of linear regression in this instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 7.4\n",
    "\n",
    "Create a Decision Tree to forecast \"total\" by manually iterating over the features \"hour\" and \"workingday\". The algorithm must at least have 6 end nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.5\n",
    "\n",
    "Train a Decision Tree using scikit-learn. Comment about the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.844262        5.0             1.0       1.0  ...   \n",
       "1                  0.815789        9.0             4.0       1.0  ...   \n",
       "2                  0.775701        4.0             3.0       1.0  ...   \n",
       "3                  0.677350       10.0             3.0       1.0  ...   \n",
       "4                  0.830357        3.0             2.0       1.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6000.000000\n",
       "mean        0.500000\n",
       "std         0.500042\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.500000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: Popular, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>358.138833</td>\n",
       "      <td>10.368667</td>\n",
       "      <td>547.428833</td>\n",
       "      <td>0.527732</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.665823</td>\n",
       "      <td>11.874000</td>\n",
       "      <td>3.272500</td>\n",
       "      <td>4.954667</td>\n",
       "      <td>1.463167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357497</td>\n",
       "      <td>0.097194</td>\n",
       "      <td>0.762009</td>\n",
       "      <td>-0.265334</td>\n",
       "      <td>-0.530531</td>\n",
       "      <td>-0.110047</td>\n",
       "      <td>0.296854</td>\n",
       "      <td>0.077178</td>\n",
       "      <td>0.343496</td>\n",
       "      <td>0.167633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>210.734614</td>\n",
       "      <td>2.106140</td>\n",
       "      <td>510.232776</td>\n",
       "      <td>0.148356</td>\n",
       "      <td>0.192815</td>\n",
       "      <td>0.167740</td>\n",
       "      <td>13.444103</td>\n",
       "      <td>4.262895</td>\n",
       "      <td>8.635916</td>\n",
       "      <td>4.508144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112586</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.256845</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.294477</td>\n",
       "      <td>0.100482</td>\n",
       "      <td>0.334117</td>\n",
       "      <td>0.282790</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0.240462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>0.465950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619624</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308693</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>345.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>0.541477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364237</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.260185</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>544.250000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>0.614980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756237</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419669</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.191273</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  6000.000000     6000.000000       6000.000000      6000.000000   \n",
       "mean    358.138833       10.368667        547.428833         0.527732   \n",
       "std     210.734614        2.106140        510.232776         0.148356   \n",
       "min       9.000000        3.000000          0.000000         0.000000   \n",
       "25%     175.000000        9.000000        231.000000         0.465950   \n",
       "50%     345.000000       10.000000        391.000000         0.541477   \n",
       "75%     544.250000       12.000000        719.000000         0.614980   \n",
       "max     731.000000       19.000000       8474.000000         0.967742   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens    num_hrefs  \\\n",
       "count       6000.000000               6000.000000  6000.000000   \n",
       "mean           0.961333                  0.665823    11.874000   \n",
       "std            0.192815                  0.167740    13.444103   \n",
       "min            0.000000                  0.000000     0.000000   \n",
       "25%            1.000000                  0.619624     4.000000   \n",
       "50%            1.000000                  0.689119     8.000000   \n",
       "75%            1.000000                  0.756237    15.000000   \n",
       "max            1.000000                  1.000000   304.000000   \n",
       "\n",
       "       num_self_hrefs     num_imgs   num_videos  ...  avg_positive_polarity  \\\n",
       "count     6000.000000  6000.000000  6000.000000  ...            6000.000000   \n",
       "mean         3.272500     4.954667     1.463167  ...               0.357497   \n",
       "std          4.262895     8.635916     4.508144  ...               0.112586   \n",
       "min          0.000000     0.000000     0.000000  ...               0.000000   \n",
       "25%          1.000000     1.000000     0.000000  ...               0.308693   \n",
       "50%          2.000000     1.000000     0.000000  ...               0.364237   \n",
       "75%          4.000000     7.000000     1.000000  ...               0.419669   \n",
       "max        116.000000   111.000000    91.000000  ...               1.000000   \n",
       "\n",
       "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "count            6000.000000            6000.000000            6000.000000   \n",
       "mean                0.097194               0.762009              -0.265334   \n",
       "std                 0.076585               0.256845               0.133800   \n",
       "min                 0.000000               0.000000              -1.000000   \n",
       "25%                 0.050000               0.600000              -0.340000   \n",
       "50%                 0.100000               0.800000              -0.260185   \n",
       "75%                 0.100000               1.000000              -0.191273   \n",
       "max                 1.000000               1.000000               0.000000   \n",
       "\n",
       "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "count            6000.000000            6000.000000         6000.000000   \n",
       "mean               -0.530531              -0.110047            0.296854   \n",
       "std                 0.294477               0.100482            0.334117   \n",
       "min                -1.000000              -1.000000            0.000000   \n",
       "25%                -0.714286              -0.125000            0.000000   \n",
       "50%                -0.500000              -0.100000            0.200000   \n",
       "75%                -0.300000              -0.050000            0.500000   \n",
       "max                 0.000000               0.000000            1.000000   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "count               6000.000000             6000.000000   \n",
       "mean                   0.077178                0.343496   \n",
       "std                    0.282790                0.186815   \n",
       "min                   -1.000000                0.000000   \n",
       "25%                    0.000000                0.166667   \n",
       "50%                    0.000000                0.500000   \n",
       "75%                    0.166667                0.500000   \n",
       "max                    1.000000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity  \n",
       "count                   6000.000000  \n",
       "mean                       0.167633  \n",
       "std                        0.240462  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.016667  \n",
       "75%                        0.250000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train                            Test\n",
      "-----------------------------  ------\n",
      "count    4500.000000             1500\n",
      "mean        0.502444\n",
      "std         0.500050\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: Popular, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "# Train vs test\n",
    "table = [[y_train.describe(), y_test.describe()[-0]]]\n",
    "headers = ['Train', 'Test']\n",
    "print(tabulate(table,headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.6\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regression\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of values to try for max_depth\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# list to store the average RMSE for each value of max_depth\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_depth\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy 0.6304444444444444\n",
      "Max Depth 3\n"
     ]
    }
   ],
   "source": [
    "# show the best accuracy and the corresponding max_depth\n",
    "tunning=sorted(zip(accuracy_scores, max_depth_range))[::-1][0]\n",
    "print(\"Best accuracy\",tunning[0])\n",
    "print(\"Max Depth\",tunning[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once best max_depth is selected, so fit a tree using that parameter\n",
    "clf = DecisionTreeClassifier(max_depth=tunning[1], random_state=123)\n",
    "accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy').mean())\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kw_avg_avg</td>\n",
       "      <td>0.719798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kw_min_max</td>\n",
       "      <td>0.104722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kw_max_avg</td>\n",
       "      <td>0.090037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kw_avg_min</td>\n",
       "      <td>0.049868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kw_avg_max</td>\n",
       "      <td>0.035574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timedelta</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weekday_is_wednesday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>weekday_is_friday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>weekday_is_saturday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>weekday_is_sunday</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  importance\n",
       "26            kw_avg_avg    0.719798\n",
       "21            kw_min_max    0.104722\n",
       "25            kw_max_avg    0.090037\n",
       "20            kw_avg_min    0.049868\n",
       "23            kw_avg_max    0.035574\n",
       "0              timedelta    0.000000\n",
       "32  weekday_is_wednesday    0.000000\n",
       "34     weekday_is_friday    0.000000\n",
       "35   weekday_is_saturday    0.000000\n",
       "36     weekday_is_sunday    0.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute feature importances\n",
    "feature_cols = X.columns[X.columns.str.startswith('C') == False]\n",
    "\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':clf.feature_importances_}).sort_values('importance',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real                           Predict\n",
      "-----------------------------  -----------------------\n",
      "count    1500.000000           count    1500.000000\n",
      "mean        0.492667           mean        0.462667\n",
      "std         0.500113           std         0.498771\n",
      "min         0.000000           min         0.000000\n",
      "25%         0.000000           25%         0.000000\n",
      "50%         0.000000           50%         0.000000\n",
      "75%         1.000000           75%         1.000000\n",
      "max         1.000000           max         1.000000\n",
      "Name: Popular, dtype: float64  Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred=pd.DataFrame(y_pred)\n",
    "\n",
    "# Real vs predict\n",
    "table = [[y_test.describe(), y_pred.describe()[-0]]]\n",
    "headers = ['Real', 'Predict']\n",
    "print(tabulate(table,headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[522, 239],\n",
       "       [284, 455]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6513333333333333\n",
      "F1 score: 0.6350314026517794\n",
      "Precision: 0.6556195965417867\n",
      "Recall: 0.6156968876860622\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "y_pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[501, 260],\n",
       "       [258, 481]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6546666666666666\n",
      "F1 score: 0.6500000000000001\n",
      "Precision: 0.6491228070175439\n",
      "Recall: 0.6508795669824087\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.7\n",
    "\n",
    "i) Estimate 300 bagged samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 300 bagged samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "seed=np.random.seed(123)\n",
    "\n",
    "# number of bagged samples\n",
    "B=300\n",
    "\n",
    "# model\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=B, \n",
    "                          bootstrap=True, oob_score=True, random_state=seed)\n",
    "\n",
    "# fit and predict\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real                           Predict\n",
      "-----------------------------  -----------------------\n",
      "count    1500.000000           count    1500.000000\n",
      "mean        0.492667           mean        0.497867\n",
      "std         0.500113           std         0.175126\n",
      "min         0.000000           min         0.026667\n",
      "25%         0.000000           25%         0.376667\n",
      "50%         0.000000           50%         0.503333\n",
      "75%         1.000000           75%         0.626667\n",
      "max         1.000000           max         0.930000\n",
      "Name: Popular, dtype: float64  Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Real vs predict\n",
    "table = [[y_test.describe(), y_pred.describe()[-0]]]\n",
    "headers = ['Real', 'Predict']\n",
    "print(tabulate(table,headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46052597948191565"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 Decision Trees where max_depth=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 100\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3444    1\n",
       "1307    0\n",
       "2007    1\n",
       "4756    1\n",
       "1655    1\n",
       "       ..\n",
       "3956    1\n",
       "4065    0\n",
       "5754    1\n",
       "894     1\n",
       "3647    0\n",
       "Name: Popular, Length: 4500, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the rows for the first decision tree\n",
    "y_train.iloc[samples[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>408.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>717.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339336</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.497222</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>198.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.355556</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>620.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>0.427488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.639794</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381169</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.208165</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>422.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623693</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.360195</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>155.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>0.393728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563126</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443021</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.149074</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>-0.046528</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.046528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>383.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>0.523614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260341</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.273333</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.068182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>526.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>0.361987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508689</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346914</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.176667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>156.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.436052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.672348</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336712</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.311995</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>297.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.482877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670433</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348817</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.241163</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "3444      408.0            12.0              93.0         0.725275   \n",
       "1307      717.0            12.0             294.0         0.680851   \n",
       "2007      198.0            10.0             191.0         0.545455   \n",
       "4756      620.0             8.0            1055.0         0.427488   \n",
       "1655      422.0            11.0             468.0         0.502262   \n",
       "...         ...             ...               ...              ...   \n",
       "3956      155.0            11.0             880.0         0.393728   \n",
       "4065      383.0            11.0             498.0         0.523614   \n",
       "5754      526.0             5.0            1067.0         0.361987   \n",
       "894       156.0            11.0             999.0         0.436052   \n",
       "3647      297.0            13.0             896.0         0.482877   \n",
       "\n",
       "      n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "3444               1.0                  0.833333        5.0             4.0   \n",
       "1307               1.0                  0.863636       15.0             0.0   \n",
       "2007               1.0                  0.524390        4.0             4.0   \n",
       "4756               1.0                  0.639794       15.0             0.0   \n",
       "1655               1.0                  0.623693       31.0             5.0   \n",
       "...                ...                       ...        ...             ...   \n",
       "3956               1.0                  0.563126       12.0             1.0   \n",
       "4065               1.0                  0.661342       10.0             0.0   \n",
       "5754               1.0                  0.508689       11.0             3.0   \n",
       "894                1.0                  0.672348        9.0             0.0   \n",
       "3647               1.0                  0.670433        9.0             2.0   \n",
       "\n",
       "      num_imgs  num_videos  ...  avg_positive_polarity  min_positive_polarity  \\\n",
       "3444       1.0         1.0  ...               0.442857               0.285714   \n",
       "1307       1.0         0.0  ...               0.339336               0.050000   \n",
       "2007      15.0         0.0  ...               0.739394               0.136364   \n",
       "4756       1.0         0.0  ...               0.381169               0.033333   \n",
       "1655      26.0         1.0  ...               0.473333               0.200000   \n",
       "...        ...         ...  ...                    ...                    ...   \n",
       "3956       1.0         1.0  ...               0.443021               0.100000   \n",
       "4065       1.0         1.0  ...               0.260341               0.100000   \n",
       "5754       9.0         0.0  ...               0.346914               0.100000   \n",
       "894        1.0         0.0  ...               0.336712               0.050000   \n",
       "3647       1.0         0.0  ...               0.348817               0.100000   \n",
       "\n",
       "      max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "3444                   0.60              -0.155556              -0.155556   \n",
       "1307                   0.70              -0.497222              -1.000000   \n",
       "2007                   1.00              -0.355556              -0.433333   \n",
       "4756                   0.90              -0.208165              -0.600000   \n",
       "1655                   1.00              -0.360195              -0.800000   \n",
       "...                     ...                    ...                    ...   \n",
       "3956                   1.00              -0.149074              -0.250000   \n",
       "4065                   0.85              -0.273333              -0.600000   \n",
       "5754                   1.00              -0.176667              -0.500000   \n",
       "894                    0.90              -0.311995              -1.000000   \n",
       "3647                   0.80              -0.241163              -0.500000   \n",
       "\n",
       "      max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "3444              -0.155556            0.000000                  0.000000   \n",
       "1307              -0.155556            0.100000                  0.050000   \n",
       "2007              -0.200000            0.000000                  0.000000   \n",
       "4756              -0.050000            0.000000                  0.000000   \n",
       "1655              -0.071429            0.800000                  0.400000   \n",
       "...                     ...                 ...                       ...   \n",
       "3956              -0.050000            0.394444                 -0.046528   \n",
       "4065              -0.100000            0.275000                  0.068182   \n",
       "5754              -0.050000            0.300000                  1.000000   \n",
       "894               -0.100000            0.300000                  0.100000   \n",
       "3647              -0.050000            0.700000                 -0.500000   \n",
       "\n",
       "      abs_title_subjectivity  abs_title_sentiment_polarity  \n",
       "3444                0.500000                      0.000000  \n",
       "1307                0.400000                      0.050000  \n",
       "2007                0.500000                      0.000000  \n",
       "4756                0.500000                      0.000000  \n",
       "1655                0.300000                      0.400000  \n",
       "...                      ...                           ...  \n",
       "3956                0.105556                      0.046528  \n",
       "4065                0.225000                      0.068182  \n",
       "5754                0.200000                      1.000000  \n",
       "894                 0.200000                      0.100000  \n",
       "3647                0.200000                      0.500000  \n",
       "\n",
       "[4500 rows x 59 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   90   91   92  \\\n",
       "0     0.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  1.0  0.0   \n",
       "1     1.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  ...  0.0  1.0  1.0   \n",
       "2     1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  0.0  ...  1.0  1.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0   \n",
       "4     1.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  ...  1.0  1.0  1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1495  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "1496  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  ...  1.0  1.0  1.0   \n",
       "1497  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  1.0   \n",
       "1498  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  1.0   \n",
       "1499  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  ...  1.0  0.0  1.0   \n",
       "\n",
       "       93   94   95   96   97   98   99  \n",
       "0     0.0  0.0  1.0  1.0  0.0  1.0  1.0  \n",
       "1     0.0  1.0  0.0  1.0  1.0  0.0  1.0  \n",
       "2     1.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "4     1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1495  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1496  0.0  0.0  1.0  1.0  1.0  1.0  0.0  \n",
       "1497  0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "1498  1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "1499  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "\n",
       "[1500 rows x 100 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grow each tree deep\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame for storing predicted price from each tree\n",
    "y_pred = []\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i in range(n_B):\n",
    "    X_train_tree = X_train.iloc[samples[i], :]\n",
    "    y_train_tree = y_train.iloc[samples[i]]\n",
    "    treereg.fit(X_train_tree, y_train_tree)\n",
    "    y_pred.append(treereg.predict(X_test))\n",
    "    \n",
    "y_pred = np.transpose(pd.DataFrame(y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "1495    0\n",
       "1496    1\n",
       "1497    0\n",
       "1498    0\n",
       "1499    0\n",
       "Length: 1500, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Results of the ensemble\n",
    "#y_pred_mean = y_pred.mean(axis=1)\n",
    "y_pred_mean = (np.mean(y_pred, axis=1) >= 0.5).astype(np.int)\n",
    "y_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5796550698475775"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "np.sqrt(mean_squared_error(y_test, y_pred_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 Decision Trees where max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 100\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412621</td>\n",
       "      <td>0.435723</td>\n",
       "      <td>0.431058</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>0.445018</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.429190</td>\n",
       "      <td>0.507395</td>\n",
       "      <td>0.459665</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.404867</td>\n",
       "      <td>0.405301</td>\n",
       "      <td>0.287321</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>0.415706</td>\n",
       "      <td>0.293255</td>\n",
       "      <td>0.431415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412621</td>\n",
       "      <td>0.435723</td>\n",
       "      <td>0.431058</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>0.445018</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.429190</td>\n",
       "      <td>0.507395</td>\n",
       "      <td>0.459665</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.404867</td>\n",
       "      <td>0.405301</td>\n",
       "      <td>0.451145</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>0.415706</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>0.431415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577342</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>0.698652</td>\n",
       "      <td>0.691348</td>\n",
       "      <td>0.719873</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.295652</td>\n",
       "      <td>0.669519</td>\n",
       "      <td>0.579420</td>\n",
       "      <td>0.589255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.608789</td>\n",
       "      <td>0.675708</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>0.576594</td>\n",
       "      <td>0.614301</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>0.712302</td>\n",
       "      <td>0.726384</td>\n",
       "      <td>0.600420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412621</td>\n",
       "      <td>0.435723</td>\n",
       "      <td>0.431058</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>0.266885</td>\n",
       "      <td>0.289928</td>\n",
       "      <td>0.429190</td>\n",
       "      <td>0.374625</td>\n",
       "      <td>0.459665</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297175</td>\n",
       "      <td>0.404867</td>\n",
       "      <td>0.405301</td>\n",
       "      <td>0.451145</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.471050</td>\n",
       "      <td>0.415706</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>0.431415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.595928</td>\n",
       "      <td>0.538329</td>\n",
       "      <td>0.691348</td>\n",
       "      <td>0.572209</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.637939</td>\n",
       "      <td>0.669519</td>\n",
       "      <td>0.726221</td>\n",
       "      <td>0.589255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603322</td>\n",
       "      <td>0.608789</td>\n",
       "      <td>0.512164</td>\n",
       "      <td>0.727825</td>\n",
       "      <td>0.738120</td>\n",
       "      <td>0.614301</td>\n",
       "      <td>0.725153</td>\n",
       "      <td>0.564648</td>\n",
       "      <td>0.726384</td>\n",
       "      <td>0.754453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.577342</td>\n",
       "      <td>0.595928</td>\n",
       "      <td>0.538329</td>\n",
       "      <td>0.546627</td>\n",
       "      <td>0.572209</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.295652</td>\n",
       "      <td>0.507395</td>\n",
       "      <td>0.726221</td>\n",
       "      <td>0.589255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603322</td>\n",
       "      <td>0.608789</td>\n",
       "      <td>0.512164</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>0.576594</td>\n",
       "      <td>0.614301</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.564648</td>\n",
       "      <td>0.587255</td>\n",
       "      <td>0.600420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0.577342</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>0.698652</td>\n",
       "      <td>0.546627</td>\n",
       "      <td>0.719873</td>\n",
       "      <td>0.289928</td>\n",
       "      <td>0.637939</td>\n",
       "      <td>0.374625</td>\n",
       "      <td>0.726221</td>\n",
       "      <td>0.589255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603322</td>\n",
       "      <td>0.608789</td>\n",
       "      <td>0.675708</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>0.576594</td>\n",
       "      <td>0.614301</td>\n",
       "      <td>0.471050</td>\n",
       "      <td>0.564648</td>\n",
       "      <td>0.587255</td>\n",
       "      <td>0.600420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.412621</td>\n",
       "      <td>0.435723</td>\n",
       "      <td>0.431058</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>0.266885</td>\n",
       "      <td>0.289928</td>\n",
       "      <td>0.429190</td>\n",
       "      <td>0.374625</td>\n",
       "      <td>0.459665</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297175</td>\n",
       "      <td>0.404867</td>\n",
       "      <td>0.405301</td>\n",
       "      <td>0.451145</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.471050</td>\n",
       "      <td>0.415706</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>0.431415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0.209354</td>\n",
       "      <td>0.435723</td>\n",
       "      <td>0.431058</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>0.445018</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.246020</td>\n",
       "      <td>0.507395</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.213808</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>0.287321</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.293255</td>\n",
       "      <td>0.208920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.209354</td>\n",
       "      <td>0.247588</td>\n",
       "      <td>0.227414</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>0.266885</td>\n",
       "      <td>0.289928</td>\n",
       "      <td>0.246020</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.459665</td>\n",
       "      <td>0.401493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297175</td>\n",
       "      <td>0.213808</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>0.451145</td>\n",
       "      <td>0.303011</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.471050</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>0.208920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.412621  0.435723  0.431058  0.334364  0.445018  0.503704  0.429190   \n",
       "1     0.412621  0.435723  0.431058  0.334364  0.445018  0.503704  0.429190   \n",
       "2     0.577342  0.729400  0.698652  0.691348  0.719873  0.677800  0.295652   \n",
       "3     0.412621  0.435723  0.431058  0.334364  0.266885  0.289928  0.429190   \n",
       "4     0.730488  0.595928  0.538329  0.691348  0.572209  0.677800  0.637939   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1495  0.577342  0.595928  0.538329  0.546627  0.572209  0.503704  0.295652   \n",
       "1496  0.577342  0.729400  0.698652  0.546627  0.719873  0.289928  0.637939   \n",
       "1497  0.412621  0.435723  0.431058  0.334364  0.266885  0.289928  0.429190   \n",
       "1498  0.209354  0.435723  0.431058  0.334364  0.445018  0.503704  0.246020   \n",
       "1499  0.209354  0.247588  0.227414  0.334364  0.266885  0.289928  0.246020   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.507395  0.459665  0.401493  ...  0.438849  0.404867  0.405301   \n",
       "1     0.507395  0.459665  0.401493  ...  0.438849  0.404867  0.405301   \n",
       "2     0.669519  0.579420  0.589255  ...  0.741667  0.608789  0.675708   \n",
       "3     0.374625  0.459665  0.401493  ...  0.297175  0.404867  0.405301   \n",
       "4     0.669519  0.726221  0.589255  ...  0.603322  0.608789  0.512164   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1495  0.507395  0.726221  0.589255  ...  0.603322  0.608789  0.512164   \n",
       "1496  0.374625  0.726221  0.589255  ...  0.603322  0.608789  0.675708   \n",
       "1497  0.374625  0.459665  0.401493  ...  0.297175  0.404867  0.405301   \n",
       "1498  0.507395  0.295833  0.401493  ...  0.438849  0.213808  0.198830   \n",
       "1499  0.176471  0.459665  0.401493  ...  0.297175  0.213808  0.198830   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.287321  0.515982  0.414365  0.566281  0.415706  0.293255  0.431415  \n",
       "1     0.451145  0.303011  0.414365  0.566281  0.415706  0.455655  0.431415  \n",
       "2     0.587473  0.576594  0.614301  0.566281  0.712302  0.726384  0.600420  \n",
       "3     0.451145  0.303011  0.414365  0.471050  0.415706  0.455655  0.431415  \n",
       "4     0.727825  0.738120  0.614301  0.725153  0.564648  0.726384  0.754453  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1495  0.587473  0.576594  0.614301  0.312950  0.564648  0.587255  0.600420  \n",
       "1496  0.587473  0.576594  0.614301  0.471050  0.564648  0.587255  0.600420  \n",
       "1497  0.451145  0.303011  0.414365  0.471050  0.415706  0.455655  0.431415  \n",
       "1498  0.287321  0.303011  0.414365  0.566281  0.204900  0.293255  0.208920  \n",
       "1499  0.451145  0.303011  0.414365  0.471050  0.204900  0.455655  0.208920  \n",
       "\n",
       "[1500 rows x 100 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grow each tree deep\n",
    "treereg = DecisionTreeRegressor(max_depth=2, random_state=123)\n",
    "\n",
    "# DataFrame for storing predicted price from each tree\n",
    "y_pred = []\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i in range(n_B):\n",
    "    X_train_tree = X_train.iloc[samples[i], :]\n",
    "    y_train_tree = y_train.iloc[samples[i]]\n",
    "    treereg.fit(X_train_tree, y_train_tree)\n",
    "    y_pred.append(treereg.predict(X_test))\n",
    "\n",
    "y_pred = np.transpose(pd.DataFrame(y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "1495    1\n",
       "1496    1\n",
       "1497    0\n",
       "1498    0\n",
       "1499    0\n",
       "Length: 1500, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Results of the ensemble\n",
    "#y_pred_mean = y_pred.mean(axis=1)\n",
    "y_pred_mean = (np.mean(y_pred, axis=1) >= 0.5).astype(np.int)\n",
    "y_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5904800307094785"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "np.sqrt(mean_squared_error(y_test, y_pred_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5579</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "4936   1   1   1   1   0   1   1   1   1   1  ...   1   1   1   1   1   1   1   \n",
       "761    1   0   0   0   1   1   0   0   0   1  ...   1   1   1   1   1   1   1   \n",
       "4281   0   0   0   0   0   0   1   0   0   0  ...   0   0   0   1   0   1   1   \n",
       "5579   1   1   1   1   1   1   1   1   1   1  ...   0   1   0   1   1   1   1   \n",
       "3653   0   1   1   1   1   1   1   1   1   1  ...   0   1   1   1   1   1   1   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "5218   0   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   1   0   0   \n",
       "4060   1   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   1   1   \n",
       "1346   1   0   1   1   0   1   0   1   0   1  ...   1   0   0   1   1   0   1   \n",
       "3454   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   1   0   0   1   \n",
       "3582   1   1   1   1   1   0   1   1   0   1  ...   1   0   1   1   1   1   1   \n",
       "\n",
       "      97  98  99  \n",
       "4936   1   1   1  \n",
       "761    1   1   0  \n",
       "4281   0   1   0  \n",
       "5579   1   0   1  \n",
       "3653   1   1   0  \n",
       "...   ..  ..  ..  \n",
       "5218   0   0   0  \n",
       "4060   1   1   1  \n",
       "1346   1   1   1  \n",
       "3454   0   1   0  \n",
       "3582   1   0   1  \n",
       "\n",
       "[4500 rows x 100 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123) \n",
    "n_estimators = 100\n",
    "\n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]\n",
    "\n",
    "# create\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])\n",
    "    \n",
    "X_train_2 = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    X_train_2[i] = trees[i].predict(X_train)\n",
    "\n",
    "X_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03439087, 0.03400682, 0.03525004, 0.03487362, 0.03510432,\n",
       "        0.03492571, 0.0352141 , 0.0354671 , 0.03509776, 0.03505057,\n",
       "        0.03468621, 0.03318939, 0.03501431, 0.03443667, 0.03500061,\n",
       "        0.03567682, 0.03433451, 0.03541803, 0.03469722, 0.03493   ,\n",
       "        0.03496626, 0.03440055, 0.03436068, 0.03492462, 0.03400025,\n",
       "        0.03518369, 0.03430051, 0.03429122, 0.03369941, 0.03581459,\n",
       "        0.03391153, 0.0351802 , 0.03472354, 0.03510402, 0.03597604,\n",
       "        0.03524208, 0.03456946, 0.03519206, 0.03470044, 0.03496483,\n",
       "        0.03504765, 0.03495937, 0.0345851 , 0.03511182, 0.03504363,\n",
       "        0.03420868, 0.03510403, 0.03574659, 0.03538845, 0.03503334,\n",
       "        0.03404426, 0.03441885, 0.03503623, 0.0339724 , 0.03512012,\n",
       "        0.03500518, 0.03474991, 0.03590856, 0.03469649, 0.03554311,\n",
       "        0.03450086, 0.03443209, 0.03423249, 0.03447997, 0.03391461,\n",
       "        0.03483489, 0.03602916, 0.03592495, 0.03452854, 0.03556976,\n",
       "        0.03456459, 0.03553566, 0.03459509, 0.03483013, 0.03421412,\n",
       "        0.03583045, 0.03442643, 0.0352777 , 0.03485855, 0.03517528,\n",
       "        0.0352604 , 0.03498873, 0.03491036, 0.03497274, 0.0340651 ,\n",
       "        0.03478712, 0.03513686, 0.03379146, 0.035884  , 0.03494222,\n",
       "        0.03502696, 0.03540357, 0.03467897, 0.03549046, 0.03502361,\n",
       "        0.03448916, 0.03476055, 0.0347188 , 0.03382638, 0.03495386]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(cv = 5 )\n",
    "lr.fit(X_train_2, y_train)\n",
    "\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.8\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "seed=np.random.seed(123)\n",
    "\n",
    "# number of bagged samples\n",
    "B=300\n",
    "\n",
    "# model\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=B, bootstrap=True,\n",
    "                        random_state=seed, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# fit and predict\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real                           Predict\n",
      "-----------------------------  -----------------------\n",
      "count    1500.000000           count    1500.000000\n",
      "mean        0.492667           mean        0.507333\n",
      "std         0.500113           std         0.500113\n",
      "min         0.000000           min         0.000000\n",
      "25%         0.000000           25%         0.000000\n",
      "50%         0.000000           50%         1.000000\n",
      "75%         1.000000           75%         1.000000\n",
      "max         1.000000           max         1.000000\n",
      "Name: Popular, dtype: float64  Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Real vs predict\n",
    "table = [[y_test.describe(), y_pred.describe()[-0]]]\n",
    "headers = ['Real', 'Predict']\n",
    "print(tabulate(table,headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6613333333333333\n",
      "F1 score: 0.6613333333333333\n",
      "Precision: 0.6517739816031537\n",
      "Recall: 0.6711772665764547\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.9\n",
    "\n",
    "i) Estimate the probability as %models that predict positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>761</td>\n",
       "      <td>0.507333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>739</td>\n",
       "      <td>0.492667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  percentage\n",
       "0                   \n",
       "1    761    0.507333\n",
       "0    739    0.492667"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.10\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "seed=np.random.seed(123)\n",
    "\n",
    "# number of bagged samples\n",
    "B=300\n",
    "\n",
    "# model\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=B, bootstrap=True,\n",
    "                        random_state=seed, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# fit and predict\n",
    "clf.fit(X_train, y_train)\n",
    "errors = np.zeros(clf.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "    oob_sample = ~clf.estimators_samples_[i]\n",
    "    y_pred_ = clf.estimators_[i].predict(X_train.values[oob_sample])\n",
    "    errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "y_pred = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int)\n",
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real                           Predict\n",
      "-----------------------------  -----------------------\n",
      "count    1500.000000           count    1500.000000\n",
      "mean        0.492667           mean        0.513333\n",
      "std         0.500113           std         0.499989\n",
      "min         0.000000           min         0.000000\n",
      "25%         0.000000           25%         0.000000\n",
      "50%         0.000000           50%         1.000000\n",
      "75%         1.000000           75%         1.000000\n",
      "max         1.000000           max         1.000000\n",
      "Name: Popular, dtype: float64  Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Real vs predict\n",
    "table = [[y_test.describe(), y_pred.describe()[-0]]]\n",
    "headers = ['Real', 'Predict']\n",
    "print(tabulate(table,headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6646666666666666\n",
      "F1 score: 0.6666666666666667\n",
      "Precision: 0.6532467532467533\n",
      "Recall: 0.6806495263870095\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.11\n",
    "\n",
    "i) Estimate the probability of the weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770</td>\n",
       "      <td>0.513333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  percentage\n",
       "0                   \n",
       "1    770    0.513333\n",
       "0    730    0.486667"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.12\n",
    "\n",
    "i) Estimate a logistic regression using as input the estimated classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
